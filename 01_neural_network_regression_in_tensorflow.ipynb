{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_neural_network_regression_in_tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1SelvZhnauLrnmolaYdLyJIVZVfaz51XJ",
      "authorship_tag": "ABX9TyPncnLSs07zPuW4oztQBC36",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sushii-00/DanielBourke_DL_Course/blob/main/01_neural_network_regression_in_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruRlfQEW-nXA"
      },
      "source": [
        "#Introduction to regression with neural networks in tensorflow\n",
        "\n",
        "There are many definitions for a regression problem but in our  case, we're going to simplify it:\n",
        "\n",
        "* predicting a numerical variable based on some other combination of variables, even shorter... predicting a number."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrMh63RIDyy-",
        "outputId": "9352c51d-fd75-4ad2-fc58-edb1470315fb"
      },
      "source": [
        "#import tensorflow \n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJcFOod2EH8P"
      },
      "source": [
        "## creating some data to view and fit\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "qanRf2KSEXl5",
        "outputId": "95009f77-cd91-4b49-db2d-e5400c010478"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# creating features\n",
        "X = np.array([-7.0,-4.0,-1.0,2.0,5.0,8.0,11.0,14.0])\n",
        "\n",
        "# creating labels\n",
        "\n",
        "y = np.array([3.0,6.0,9.0,12.0,15.0,18.0,21.0,24.0])\n",
        "\n",
        "# visualise it:\n",
        "\n",
        "plt.scatter(X,y);\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmL-nXJCEXo3",
        "outputId": "cacd900f-8f4e-43f8-ab3c-a6b0ead62b59"
      },
      "source": [
        "X+10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSzb7rH6EXsD",
        "outputId": "6b0498b6-d73a-4a31-9665-29e30db6e91f"
      },
      "source": [
        "y == X+10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True,  True,  True,  True,  True,  True])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yo_0KvLaEXu-"
      },
      "source": [
        "## input and output shapes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Dsfti4tFW_y",
        "outputId": "a99ad609-303b-4df2-885c-39a64b5dc362"
      },
      "source": [
        "# create a demo tensor for our housing price prediction problem\n",
        "\n",
        "house_info = tf.constant([\"bedroom\", \"bathroom\",\"garage\"])\n",
        "house_price = tf.constant([939700])\n",
        "house_info, house_price"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'bedroom', b'bathroom', b'garage'], dtype=object)>,\n",
              " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([939700], dtype=int32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6QhqQMEFXCd",
        "outputId": "9e1a5336-0a16-4c2d-9547-d2bfbb5b7470"
      },
      "source": [
        "input_shape = X.shape\n",
        "output_shape = y.shape\n",
        "input_shape , output_shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8,), (8,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNaqCACVFXE9",
        "outputId": "5ae6d689-8b20-4568-b7b8-c8396052917c"
      },
      "source": [
        " X[0], y[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-7.0, 3.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRyvupk1FXHo",
        "outputId": "a01669c2-045a-4c4c-b0a7-da553d05b9b8"
      },
      "source": [
        "X[1],y[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-4.0, 6.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-h7QZxNFXJ9",
        "outputId": "c4955699-33c2-49e0-c66e-65cf8c673612"
      },
      "source": [
        "input_shape = X[0].shape\n",
        "output_shape = y[0].shape\n",
        "input_shape , output_shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((), ())"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiPRSOFkFXMH",
        "outputId": "16a40c81-414d-466c-bbff-e598cda72c13"
      },
      "source": [
        "X[0].ndim"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "op9WM3MkFXOv",
        "outputId": "3c706f02-0feb-45b2-94f1-8801c0b82a97"
      },
      "source": [
        "# turn numpy arrays into tensors with data type float32\n",
        "X = tf.cast(tf.constant(X), dtype=tf.float32)\n",
        "y = tf.cast(tf.constant(y),dtype= tf.float32)\n",
        "X,y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5s50NEHFXRj",
        "outputId": "cb69a74e-72b9-44bc-df7c-059e7174fe64"
      },
      "source": [
        "input_shape = X[0].shape\n",
        "output_shape = y[0].shape\n",
        "input_shape , output_shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([]), TensorShape([]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "4EkG2P_fFXT9",
        "outputId": "60fb6cf8-5cda-422f-b243-2b58e96a47af"
      },
      "source": [
        "plt.scatter(X,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7fbf031bba10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxd3Jd7RraSb"
      },
      "source": [
        "## steps in modelling with tensorflow\n",
        "\n",
        "1. **Creating a model**- define the input and output layers, as well as the hidden layers of a deep learning model.\n",
        "2. **Compiling a model**- define the loss function (in other words, the function which tells our model how wrong it is) and the optimiser (tells our model how to improve its patterns its learning) and evaluation metrics (what we can use to interpret the performance of our model).\n",
        "3. Fitting a model - letting the model try to find patterns between X and y (features and labels)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vNXsw_Ire2D",
        "outputId": "186172bb-abc6-420e-afce-f2a061d9d180"
      },
      "source": [
        "# set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model using the Sequential API\n",
        "model = tf.keras.Sequential([\n",
        "                  tf.keras.layers.Dense(1)])\n",
        "\n",
        "# 2. compile the model\n",
        "model.compile(loss=tf.keras.losses.mae,  #mae= mean absolute error; error is the difference absolutes and predictions \n",
        "              optimizer=tf.keras.optimizers.SGD(), #sgd is short for stochatic gradient descend                          \n",
        "              metrics= [\"mae\"])\n",
        "\n",
        "# 3. fit the model\n",
        "model.fit(X, y, epochs=5) # epochs => can be defined as X and y are given to the model and it has 5(here) opportunities to go throgh X and y totally befor giving us the final predictions or declaring that the model is trained.\n",
        "\n",
        "\n",
        "              \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1/1 [==============================] - 0s 351ms/step - loss: 11.5048 - mae: 11.5048\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 11.3723 - mae: 11.3723\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.2398 - mae: 11.2398\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 11.1073 - mae: 11.1073\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.9748 - mae: 10.9748\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbf03ee4cd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5m5WiCrre4p",
        "outputId": "c70b827f-3b30-4d50-e9e3-72934172032a"
      },
      "source": [
        "# check out X and y\n",
        "X,y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpQQgc0Gre7E",
        "outputId": "f57583bb-724f-4d7c-8549-f16193201470"
      },
      "source": [
        "#Try and make prediction using our model\n",
        "y_pred = model.predict([17.0])\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[12.716021]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9FOf1sbre-a",
        "outputId": "e795b781-5d21-4d6b-e1f4-8c18126e050f"
      },
      "source": [
        "y_pred + 11 # we added the error to check if our model is only as off as if we added the error to our result our prediction would fall right into place"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[23.71602]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIOv9qIoy_kv"
      },
      "source": [
        "# but that is still pretty off."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5OLZ7EOzD5d"
      },
      "source": [
        "### IMPROVING OUR MODEL\n",
        "We can improve our model, by altering the steps we took to create a model.\n",
        "\n",
        "1. **Creating a model** - here we might add more layers, increase the number of hidden units (also called as neurons) within each of the hidden layers, change the activation function of each layer.\n",
        "2. **Compiling a model** - Here, we might change the optimisation function or perhaps the **learning rate** of the optimisation function.\n",
        "3. **Fitting a model** - Here, we might fet a model for more **epochs** (leave it training for longer) or on more data (give the model more examples to learn from)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qc_wNCu8I2t6"
      },
      "source": [
        "# common ways of improving a model\n",
        "* adding layers\n",
        "* Increase the number of layers\n",
        "* change the activation functions\n",
        "* change the optimization function\n",
        "* change the learning rate\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_grcLOrDFxo"
      },
      "source": [
        "###let's create a more optimised and a more **DEEP** model\n",
        "\n",
        "* but let's do 1 step at a time:\n",
        "let us first just increase the number of times the model looks at the dataset. That is, lets increase the number of epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYFLDm53F9Q4",
        "outputId": "d7fc7b84-af17-4b4d-ef57-9eb055b0020b"
      },
      "source": [
        "#1. create the model\n",
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Dense(1)\n",
        "                             ])\n",
        "\n",
        "#2. Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n",
        "#3. Fit the model(but this time make it look longer at the training set)\n",
        "model.fit(X,y,epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 268ms/step - loss: 11.2219 - mae: 11.2219\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 11.0894 - mae: 11.0894\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.9569 - mae: 10.9569\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.8244 - mae: 10.8244\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.6919 - mae: 10.6919\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 10.5594 - mae: 10.5594\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.4269 - mae: 10.4269\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.2944 - mae: 10.2944\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 10.1619 - mae: 10.1619\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 10.0294 - mae: 10.0294\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.8969 - mae: 9.8969\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.7644 - mae: 9.7644\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.6319 - mae: 9.6319\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.4994 - mae: 9.4994\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.3669 - mae: 9.3669\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 9.2344 - mae: 9.2344\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.1019 - mae: 9.1019\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 8.9694 - mae: 8.9694\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 8.8369 - mae: 8.8369\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 8.7044 - mae: 8.7044\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.5719 - mae: 8.5719\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.4394 - mae: 8.4394\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3069 - mae: 8.3069\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.1744 - mae: 8.1744\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 8.0419 - mae: 8.0419\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 7.9094 - mae: 7.9094\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.7769 - mae: 7.7769\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 7.6444 - mae: 7.6444\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 7.5119 - mae: 7.5119\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.3794 - mae: 7.3794\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.2750 - mae: 7.2750\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.2694 - mae: 7.2694\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.2638 - mae: 7.2638\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.2581 - mae: 7.2581\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.2525 - mae: 7.2525\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.2469 - mae: 7.2469\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 7.2412 - mae: 7.2412\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.2356 - mae: 7.2356\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2300 - mae: 7.2300\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 7.2244 - mae: 7.2244\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.2188 - mae: 7.2188\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.2131 - mae: 7.2131\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 7.2075 - mae: 7.2075\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.2019 - mae: 7.2019\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.1962 - mae: 7.1962\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.1906 - mae: 7.1906\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1850 - mae: 7.1850\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.1794 - mae: 7.1794\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.1737 - mae: 7.1737\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1681 - mae: 7.1681\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1625 - mae: 7.1625\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.1569 - mae: 7.1569\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1512 - mae: 7.1512\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.1456 - mae: 7.1456\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1400 - mae: 7.1400\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 7.1344 - mae: 7.1344\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.1287 - mae: 7.1287\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.1231 - mae: 7.1231\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1175 - mae: 7.1175\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1119 - mae: 7.1119\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.1062 - mae: 7.1062\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.1006 - mae: 7.1006\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.0950 - mae: 7.0950\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.0894 - mae: 7.0894\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0838 - mae: 7.0838\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.0781 - mae: 7.0781\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0725 - mae: 7.0725\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.0669 - mae: 7.0669\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0613 - mae: 7.0613\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.0556 - mae: 7.0556\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0500 - mae: 7.0500\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.0444 - mae: 7.0444\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0388 - mae: 7.0388\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.0331 - mae: 7.0331\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.0275 - mae: 7.0275\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0219 - mae: 7.0219\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.0163 - mae: 7.0163\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0106 - mae: 7.0106\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.0050 - mae: 7.0050\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9994 - mae: 6.9994\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.9938 - mae: 6.9938\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9881 - mae: 6.9881\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9825 - mae: 6.9825\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9769 - mae: 6.9769\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.9713 - mae: 6.9713\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9656 - mae: 6.9656\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9600 - mae: 6.9600\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9544 - mae: 6.9544\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.9488 - mae: 6.9488\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9431 - mae: 6.9431\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9375 - mae: 6.9375\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.9319 - mae: 6.9319\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9263 - mae: 6.9263\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9206 - mae: 6.9206\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9150 - mae: 6.9150\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9094 - mae: 6.9094\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9038 - mae: 6.9038\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.8981 - mae: 6.8981\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.8925 - mae: 6.8925\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.8869 - mae: 6.8869\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbefda82910>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8G3QIpcF9Tv",
        "outputId": "faf0cdad-deb0-453f-909b-2badb21d9cd2"
      },
      "source": [
        "# remind ourselves of the data\n",
        "X,y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Txmf4xdF9Vt",
        "outputId": "ec4dfe5c-3803-49b0-eefa-942782e4421d"
      },
      "source": [
        "#Let's see if our model's prediction has improved\n",
        "model.predict([17.0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[29.739855]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnlrbtlOF9Xx"
      },
      "source": [
        "# by tweeking one little parameter, we have decreased our error mutlifolds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIZuY8alI2GH"
      },
      "source": [
        "### let's try to make it more optimised. \n",
        "* epoch=100 (same as before)\n",
        "* **change** : Creating a model but this time adding one hidden layer with 100 neurons"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxBYlPCKI2it",
        "outputId": "816ef73c-fec5-47f8-98cc-8fc76bef082f"
      },
      "source": [
        "#.1. Creating a model but this time adding one hidden layer with 100 neurons\n",
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Dense(100,activation=\"relu\"),\n",
        "                             tf.keras.layers.Dense(1)\n",
        "                             ])\n",
        "# 2. compile the model\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n",
        "#3. Fit the model:\n",
        "model.fit(X,y,epochs=100)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 12.3193 - mae: 12.3193\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 11.7804 - mae: 11.7804\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 11.2324 - mae: 11.2324\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 10.6601 - mae: 10.6601\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.0632 - mae: 10.0632\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.4503 - mae: 9.4503\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.7991 - mae: 8.7991\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.1072 - mae: 8.1072\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.3691 - mae: 7.3691\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.5758 - mae: 6.5758\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.7205 - mae: 5.7205\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 4.7947 - mae: 4.7947\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.3581 - mae: 4.3581\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.3134 - mae: 4.3134\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.2550 - mae: 4.2550\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 4.2442 - mae: 4.2442\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.1520 - mae: 4.1520\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.1739 - mae: 4.1739\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 4.0681 - mae: 4.0681\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.0807 - mae: 4.0807\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.9954 - mae: 3.9954\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.9739 - mae: 3.9739\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.9208 - mae: 3.9208\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9047 - mae: 3.9047\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.9267 - mae: 3.9267\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.8797 - mae: 3.8797\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.9341 - mae: 3.9341\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.8678 - mae: 3.8678\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.9274 - mae: 3.9274\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.8751 - mae: 3.8751\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.9080 - mae: 3.9080\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.8893 - mae: 3.8893\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8834 - mae: 3.8834\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.8969 - mae: 3.8969\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8581 - mae: 3.8581\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.9046 - mae: 3.9046\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.8386 - mae: 3.8386\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9054 - mae: 3.9054\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.8482 - mae: 3.8482\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8862 - mae: 3.8862\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8605 - mae: 3.8605\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8608 - mae: 3.8608\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.8683 - mae: 3.8683\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8352 - mae: 3.8352\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8762 - mae: 3.8762\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8106 - mae: 3.8106\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.8821 - mae: 3.8821\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8234 - mae: 3.8234\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.8626 - mae: 3.8626\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.8328 - mae: 3.8328\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.8369 - mae: 3.8369\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.8408 - mae: 3.8408\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8111 - mae: 3.8111\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8489 - mae: 3.8489\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7850 - mae: 3.7850\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8585 - mae: 3.8585\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7982 - mae: 3.7982\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8377 - mae: 3.8377\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8062 - mae: 3.8062\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8117 - mae: 3.8117\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8144 - mae: 3.8144\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7856 - mae: 3.7856\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8227 - mae: 3.8227\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.7593 - mae: 3.7593\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8352 - mae: 3.8352\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7725 - mae: 3.7725\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8115 - mae: 3.8115\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7807 - mae: 3.7807\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7853 - mae: 3.7853\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.7891 - mae: 3.7891\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.7588 - mae: 3.7588\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7975 - mae: 3.7975\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7337 - mae: 3.7337\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8105 - mae: 3.8105\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.7478 - mae: 3.7478\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.7840 - mae: 3.7840\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.7563 - mae: 3.7563\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.7575 - mae: 3.7575\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7648 - mae: 3.7648\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.7307 - mae: 3.7307\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7735 - mae: 3.7735\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7125 - mae: 3.7125\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7820 - mae: 3.7820\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7242 - mae: 3.7242\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.7552 - mae: 3.7552\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.7329 - mae: 3.7329\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7284 - mae: 3.7284\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.7416 - mae: 3.7416\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7013 - mae: 3.7013\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7505 - mae: 3.7505\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.6921 - mae: 3.6921\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7522 - mae: 3.7522\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7016 - mae: 3.7016\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.7251 - mae: 3.7251\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.7105 - mae: 3.7105\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.6979 - mae: 3.6979\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7194 - mae: 3.7194\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.6705 - mae: 3.6705\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7299 - mae: 3.7299\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.6711 - mae: 3.6711\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbefc992bd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENPMR3M4I2ly",
        "outputId": "16d6a458-13d9-4cb5-d740-79bc417c3a4e"
      },
      "source": [
        "#reminding ourselves of the dataset:\n",
        "X,y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVpSC9rKI2pH",
        "outputId": "9a81de37-1dd7-444a-bcee-da81484dc013"
      },
      "source": [
        "model.predict([17.0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[31.223137]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tvS20bWI2rp"
      },
      "source": [
        "###it seems like our earlier model was performing better. This could be an **OVERFITTING PROBLEM**\n",
        "\n",
        "**Overfitting**:\n",
        "\n",
        "A statistical model is said to be overfitted, when we train it with a lot of data (just like fitting ourselves in oversized pants!).  **When a model gets trained with so much of data, it starts learning from the noise and inaccurate data entries in our data set. Then the model does not categorize the data correctly, because of too many details and noise.**\n",
        "\n",
        "The causes of overfitting are the non-parametric and non-linear methods because these types of machine learning algorithms have more freedom in building the model based on the dataset and therefore they can really build unrealistic models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgIjko6_iBx8"
      },
      "source": [
        "### let's try to make it more optimised. \n",
        "* epoch=100 (same as before)\n",
        "* Creating a model: one hidden layer with 100 neurons(same as before)\n",
        "* **change** : Creating a model but this time making activation = none"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRfBfrMyI2xX",
        "outputId": "6a080746-8c78-4cc4-9385-7875f9b8a36f"
      },
      "source": [
        "#.1. Creating a model but this time making activation = none\n",
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Dense(100,activation=None),\n",
        "                             tf.keras.layers.Dense(1)\n",
        "                             ])\n",
        "# 2. compile the model\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n",
        "#3. Fit the model:\n",
        "model.fit(X,y,epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 318ms/step - loss: 12.9917 - mae: 12.9917\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 12.4876 - mae: 12.4876\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 11.9795 - mae: 11.9795\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 11.4648 - mae: 11.4648\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.9408 - mae: 10.9408\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 10.4048 - mae: 10.4048\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.8541 - mae: 9.8541\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.2858 - mae: 9.2858\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.6971 - mae: 8.6971\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.0848 - mae: 8.0848\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.4459 - mae: 7.4459\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.2205 - mae: 7.2205\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1996 - mae: 7.1996\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1786 - mae: 7.1786\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.1575 - mae: 7.1575\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.1364 - mae: 7.1364\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1152 - mae: 7.1152\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.0940 - mae: 7.0940\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.0727 - mae: 7.0727\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.0514 - mae: 7.0514\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 7.0299 - mae: 7.0299\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 7.0084 - mae: 7.0084\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9869 - mae: 6.9869\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.9652 - mae: 6.9652\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.9434 - mae: 6.9434\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9216 - mae: 6.9216\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 6.9136 - mae: 6.9136\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.8924 - mae: 6.8924\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.8709 - mae: 6.8709\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.8493 - mae: 6.8493\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.8275 - mae: 6.8275\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.8057 - mae: 6.8057\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.7838 - mae: 6.7838\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.7617 - mae: 6.7617\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.7395 - mae: 6.7395\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.7172 - mae: 6.7172\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.6948 - mae: 6.6948\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.6722 - mae: 6.6722\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.6495 - mae: 6.6495\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.6267 - mae: 6.6267\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.6037 - mae: 6.6037\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.5806 - mae: 6.5806\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.5573 - mae: 6.5573\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.5339 - mae: 6.5339\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.5104 - mae: 6.5104\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.4866 - mae: 6.4866\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.4627 - mae: 6.4627\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.4387 - mae: 6.4387\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.4144 - mae: 6.4144\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.3936 - mae: 6.3936\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.3868 - mae: 6.3868\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.3626 - mae: 6.3626\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.3382 - mae: 6.3382\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.3136 - mae: 6.3136\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.2889 - mae: 6.2889\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.2639 - mae: 6.2639\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.2388 - mae: 6.2388\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.2134 - mae: 6.2134\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.1879 - mae: 6.1879\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.1621 - mae: 6.1621\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.1361 - mae: 6.1361\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.1098 - mae: 6.1098\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.0834 - mae: 6.0834\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.0567 - mae: 6.0567\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.0298 - mae: 6.0298\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.0026 - mae: 6.0026\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.9751 - mae: 5.9751\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.9475 - mae: 5.9475\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.9451 - mae: 5.9451\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.9181 - mae: 5.9181\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.8903 - mae: 5.8903\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.8621 - mae: 5.8621\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.8337 - mae: 5.8337\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.8051 - mae: 5.8051\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.7761 - mae: 5.7761\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.7469 - mae: 5.7469\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.7173 - mae: 5.7173\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.6875 - mae: 5.6875\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.6574 - mae: 5.6574\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 5.6269 - mae: 5.6269\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.5962 - mae: 5.5962\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.5651 - mae: 5.5651\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.5337 - mae: 5.5337\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.5095 - mae: 5.5095\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.5301 - mae: 5.5301\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.6170 - mae: 5.6170\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.4327 - mae: 5.4327\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.4002 - mae: 5.4002\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.3672 - mae: 5.3672\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.3339 - mae: 5.3339\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.3002 - mae: 5.3002\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.2662 - mae: 5.2662\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.2317 - mae: 5.2317\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.1969 - mae: 5.1969\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.1696 - mae: 5.1696\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 5.2380 - mae: 5.2380\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.2805 - mae: 5.2805\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.0846 - mae: 5.0846\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 5.0483 - mae: 5.0483\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.0116 - mae: 5.0116\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbefb838850>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRPogv0MOedT",
        "outputId": "68bff240-b0f3-49b4-a8ee-961e9cc71cef"
      },
      "source": [
        "model.predict([17.0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[29.69169]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORnYhGiUier3"
      },
      "source": [
        "### that didn't prove to make our model better. So let us try to make it better"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltd1MQpFg6J9"
      },
      "source": [
        "###THE CHANGES\n",
        "* epoch=100 (same as before)\n",
        "* Creating a model: one hidden layer with 100 neurons(same as before)\n",
        "* Creating a model with activation = none\n",
        "* compile the model but this time changing the optimizer, i.e., from SGD TO ADAM()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsmBQqrpO-GC",
        "outputId": "4c2ad77b-6598-4e2a-fa60-24306913d238"
      },
      "source": [
        "#.1. Creating a model \n",
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Dense(100,activation=None),\n",
        "                             tf.keras.layers.Dense(1)\n",
        "                             ])\n",
        "# 2. compile the model but this time changing the optimizer\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"mae\"])\n",
        "#3. Fit the model:\n",
        "model.fit(X,y,epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 354ms/step - loss: 13.4562 - mae: 13.4562\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 13.3526 - mae: 13.3526\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 13.2489 - mae: 13.2489\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 13.1452 - mae: 13.1452\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 13.0414 - mae: 13.0414\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 12.9377 - mae: 12.9377\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 12.8338 - mae: 12.8338\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 12.7300 - mae: 12.7300\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 12.6260 - mae: 12.6260\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 12.5220 - mae: 12.5220\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 12.4180 - mae: 12.4180\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 12.3138 - mae: 12.3138\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 12.2095 - mae: 12.2095\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 12.1052 - mae: 12.1052\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 12.0007 - mae: 12.0007\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 11.8960 - mae: 11.8960\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 11.7912 - mae: 11.7912\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 11.6863 - mae: 11.6863\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.5812 - mae: 11.5812\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 11.4759 - mae: 11.4759\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 11.3703 - mae: 11.3703\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 11.2646 - mae: 11.2646\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 11.1586 - mae: 11.1586\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 11.0524 - mae: 11.0524\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.9459 - mae: 10.9459\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.8391 - mae: 10.8391\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.7320 - mae: 10.7320\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.6246 - mae: 10.6246\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 10.5169 - mae: 10.5169\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.4088 - mae: 10.4088\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.3004 - mae: 10.3004\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 10.1916 - mae: 10.1916\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.0823 - mae: 10.0823\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.9727 - mae: 9.9727\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.8626 - mae: 9.8626\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.7521 - mae: 9.7521\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.6411 - mae: 9.6411\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.5296 - mae: 9.5296\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.4176 - mae: 9.4176\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.3051 - mae: 9.3051\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.1920 - mae: 9.1920\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.0784 - mae: 9.0784\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.9642 - mae: 8.9642\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.8494 - mae: 8.8494\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.7340 - mae: 8.7340\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.6180 - mae: 8.6180\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.5013 - mae: 8.5013\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.3840 - mae: 8.3840\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.2660 - mae: 8.2660\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.1473 - mae: 8.1473\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.0278 - mae: 8.0278\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.9077 - mae: 7.9077\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.7868 - mae: 7.7868\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.6651 - mae: 7.6651\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 7.5427 - mae: 7.5427\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.4194 - mae: 7.4194\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.2954 - mae: 7.2954\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.1705 - mae: 7.1705\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.0448 - mae: 7.0448\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9182 - mae: 6.9182\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.7953 - mae: 6.7953\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.7808 - mae: 6.7808\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.7666 - mae: 6.7666\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.7526 - mae: 6.7526\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.7389 - mae: 6.7389\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.7253 - mae: 6.7253\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 6.7119 - mae: 6.7119\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.6987 - mae: 6.6987\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.7012 - mae: 6.7012\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.7225 - mae: 6.7225\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.7339 - mae: 6.7339\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.7363 - mae: 6.7363\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.7304 - mae: 6.7304\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.7173 - mae: 6.7173\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.6975 - mae: 6.6975\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.6718 - mae: 6.6718\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.6408 - mae: 6.6408\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.6051 - mae: 6.6051\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.5853 - mae: 6.5853\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.5768 - mae: 6.5768\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.5679 - mae: 6.5679\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.5587 - mae: 6.5587\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.5493 - mae: 6.5493\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.5396 - mae: 6.5396\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.5296 - mae: 6.5296\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.5194 - mae: 6.5194\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.5090 - mae: 6.5090\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.4984 - mae: 6.4984\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.4876 - mae: 6.4876\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.4767 - mae: 6.4767\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.4656 - mae: 6.4656\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.4543 - mae: 6.4543\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.4429 - mae: 6.4429\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.4313 - mae: 6.4313\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.4196 - mae: 6.4196\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.4078 - mae: 6.4078\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.3958 - mae: 6.3958\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.3837 - mae: 6.3837\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.3715 - mae: 6.3715\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.3592 - mae: 6.3592\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbefa74ec50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaSXpIJiO-DU",
        "outputId": "3089fe43-0654-42b0-e75c-efdf848fc6c4"
      },
      "source": [
        "model.predict([17.0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbefa7289e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[30.44963]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ho6iLUSO-A3"
      },
      "source": [
        "### worse again"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfZ8fs_ujEt3"
      },
      "source": [
        "### THIS TIME LET US CHANGE THE LEARNING RATE OF THE OPTIMISER:\n",
        "THEREFORE,\n",
        "* epoch=100 (same as before)\n",
        "* Creating a model: one hidden layer with 100 neurons(same as before)\n",
        "* Creating a model with activation = none\n",
        "* compile the model but this time changing the optimizer, i.e., from SGD TO ADAM()\n",
        "* compile the model but this time changing the LEARNING RATE OF THE ADAM optimizer, BY DEFAULT IT WAS0.001, WE INCREASE 10 TIMES: 0.01"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95WUA_gDOka7",
        "outputId": "9a8d01ba-5f2b-4c26-b075-96fb4c44a448"
      },
      "source": [
        "#.1. Creating a model \n",
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Dense(100,activation=None),\n",
        "                             tf.keras.layers.Dense(1)\n",
        "                             ])\n",
        "# 2. compile the model but this time changing the LEARNING RATE OF THE ADAM optimizer, BY DEFAULT IT WAS 0.001, WE INCREASE 10 TIMES: 0.01\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "              metrics=[\"mae\"])\n",
        "#3. Fit the model:\n",
        "model.fit(X,y,epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 336ms/step - loss: 13.2840 - mae: 13.2840\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.2580 - mae: 12.2580\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 11.2299 - mae: 11.2299\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.1921 - mae: 10.1921\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.1385 - mae: 9.1385\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.0623 - mae: 8.0623\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9562 - mae: 6.9562\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9189 - mae: 6.9189\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.3651 - mae: 7.3651\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.8747 - mae: 7.8747\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.9717 - mae: 7.9717\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.7668 - mae: 7.7668\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.3488 - mae: 7.3488\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.8337 - mae: 6.8337\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.4526 - mae: 6.4526\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.0555 - mae: 6.0555\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.9800 - mae: 5.9800\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 6.1959 - mae: 6.1959\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.3464 - mae: 6.3464\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.3429 - mae: 6.3429\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.2072 - mae: 6.2072\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.9545 - mae: 5.9545\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.5950 - mae: 5.5950\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.2142 - mae: 5.2142\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.0502 - mae: 5.0502\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.0467 - mae: 5.0467\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5.0444 - mae: 5.0444\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.9782 - mae: 4.9782\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.8523 - mae: 4.8523\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 4.6706 - mae: 4.6706\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.4368 - mae: 4.4368\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.1545 - mae: 4.1545\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.8269 - mae: 3.8269\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.6596 - mae: 3.6596\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.6847 - mae: 3.6847\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.5922 - mae: 3.5922\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.3239 - mae: 3.3239\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.8901 - mae: 2.8901\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.5453 - mae: 2.5453\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.4394 - mae: 2.4394\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2770 - mae: 2.2770\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.9529 - mae: 1.9529\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5106 - mae: 1.5106\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3192 - mae: 1.3192\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1549 - mae: 1.1549\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7742 - mae: 0.7742\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1880 - mae: 0.1880\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6749 - mae: 0.6749\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.9831 - mae: 0.9831\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0664 - mae: 1.0664\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9045 - mae: 0.9045\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1973 - mae: 1.1973\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.3117 - mae: 1.3117\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1398 - mae: 1.1398\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0087 - mae: 1.0087\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0197 - mae: 1.0197\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7893 - mae: 0.7893\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6683 - mae: 0.6683\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5684 - mae: 0.5684\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1978 - mae: 0.1978\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4706 - mae: 0.4706\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5940 - mae: 0.5940\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4382 - mae: 0.4382\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.5702 - mae: 0.5702\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7360 - mae: 0.7360\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6945 - mae: 0.6945\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4678 - mae: 0.4678\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5206 - mae: 0.5206\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5664 - mae: 0.5664\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3079 - mae: 0.3079\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2439 - mae: 0.2439\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3776 - mae: 0.3776\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2087 - mae: 0.2087\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4774 - mae: 0.4774\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6116 - mae: 0.6116\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4678 - mae: 0.4678\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1244 - mae: 0.1244\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4365 - mae: 0.4365\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4692 - mae: 0.4692\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2567 - mae: 0.2567\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3606 - mae: 0.3606\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4835 - mae: 0.4835\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3258 - mae: 0.3258\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2375 - mae: 0.2375\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3518 - mae: 0.3518\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1992 - mae: 0.1992\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2687 - mae: 0.2687\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3976 - mae: 0.3976\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2380 - mae: 0.2380\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2294 - mae: 0.2294\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2858 - mae: 0.2858\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0401 - mae: 0.0401\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3924 - mae: 0.3924\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4620 - mae: 0.4620\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2181 - mae: 0.2181\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3012 - mae: 0.3012\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4661 - mae: 0.4661\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3182 - mae: 0.3182\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1090 - mae: 0.1090\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2002 - mae: 0.2002\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbef8dea8d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RE8HE2MjQgV8",
        "outputId": "1d557870-9c39-4aae-9a9b-002fb12f1498"
      },
      "source": [
        "model.predict([17.0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbef8d3df80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[26.964045]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9ZNo4V7jZTS"
      },
      "source": [
        "###This  is the best prediction our model has made till now, which is , according to the pattern of the dataset, for 17.0 it should’ve predicted 27, because x=y+10. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6L2XRA9UQljQ"
      },
      "source": [
        "### in our case, ADJUSTING THE LEARNING RATE HAS IMPROVED THE PREDICTION MULTIFOLDS.\n",
        "AND IN MOST OF THE MODELS, **LEARNING RATE IS THE MOST IMPORTANT HYPER PARAMETER, THAT WHEN ADJUSTED, CAN MAKE MODEL'S PREDICTIONS BETTER**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDopwHxZk54M"
      },
      "source": [
        "### EVALUATING A MODEL\n",
        "\n",
        " In practice, a typical workflow you'll go through when building neural networl is:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "Building a model -> fit it -> evaluate it -> tweak the model -> fit it -> evaluate it -> tweak the model -> fit it -> evaluate it -> tweak the model -> evaluate it...\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-YcPFMuk6DV"
      },
      "source": [
        "# common ways of improving a model\n",
        "* adding layers\n",
        "* Increase the number of layers\n",
        "* change the activation functions\n",
        "* change the optimization function\n",
        "* change the learning rate\n",
        "\n",
        "###EVALUATED EARLIER. THESE ARE HYPERPARAMETERS. HYPER PARAMETERS ARE LIKE DIALS ON OUR NEURAL NETWORK MODEL THAT WE CAN ADJUST TO SEE HOW THE PERFORMANCE OF OUR MODEL CHANGES.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7O04twLk6Gu"
      },
      "source": [
        "# when it comes to evaluation. there are 3 words you should memorize:\n",
        "\n",
        "> \"VISUALISE,VISUALIZE,VISUALISE\"\n",
        "\n",
        "It's a good idea to visualise:\n",
        " * The data - what data are we working with? What does it look like?\n",
        " * The model itself- what does our model look like?\n",
        " * the training of a model - how does a model perform while it learns?\n",
        " * The predictions of the model- how do the predictions of a model line up against the ground truth(the original labels)?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZgyU6tc_XPL"
      },
      "source": [
        "### making a another (bigger) data set this time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brFg2wMWk6Jv",
        "outputId": "44c5ff8d-9361-442c-aa76-15554c191713"
      },
      "source": [
        "# Make a bigger dataset\n",
        "X = tf.range(-100,100,4)\n",
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
              "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
              "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
              "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
              "         76,   80,   84,   88,   92,   96], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5bAgp5kROBS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0956d905-d5ea-4437-c3ac-3f4569c6adaa"
      },
      "source": [
        "# make label for the dataset\n",
        "y=X+10 # this is the relation we want our model to learn\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              "array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
              "       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
              "        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
              "        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "D6-oqMZdpgTm",
        "outputId": "519ea51e-c13d-4a80-ccd8-446ce371a85b"
      },
      "source": [
        "#visualise the data\n",
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(X,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7fbef7ca13d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5vdX0Jypp7A"
      },
      "source": [
        "###The 3 sets...\n",
        "* **Training SET**- The model learns from this data, which is typically 70-80 % of the data you have available.\n",
        "\n",
        "* **Validation Set** - The model gets tuned on this data, which is typically 10-15% of the data available.\n",
        "* **Test Set** - the model gets evaluated on this data to test what it has learned, this set is typically 10-15% of the data available."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9I_TieJTsQzn"
      },
      "source": [
        "### in practice..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxqbFB72seI1",
        "outputId": "2a96760f-f061-49de-a5d2-aa69e6ddf0fd"
      },
      "source": [
        "# check the length of how many samples we have\n",
        "len(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AARNh9nseGB"
      },
      "source": [
        "# since this is still a pretty small dataset, we will skip on the validation set\n",
        " we shall use:\n",
        "\n",
        " * 80% - TRAINING SET\n",
        " * 20% - TEST SET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RJBtRHHseDw",
        "outputId": "91c0b945-7bb2-46d6-dd44-51281e792120"
      },
      "source": [
        "#Split the data into test and train sets\n",
        "X_train = X[:40] #first 40 are training samples (80% of the data)\n",
        "y_train = y[:40]\n",
        "\n",
        "X_test = X[40:] # last 10 are testing samples (20% of the data)\n",
        "y_test = y[40:]\n",
        "\n",
        "len(X_train), len(X_test), len(y_train), len(y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 10, 40, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hc7BwCKseBL"
      },
      "source": [
        "### VISUALIZING THE DATA\n",
        "Now we've got our data in training and test sets... let's visualise it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "Q1uP3eRauXip",
        "outputId": "42541531-6228-431d-bfcc-b48211e96e23"
      },
      "source": [
        "plt.figure(figsize=(10,7))\n",
        "#plot training data in blue\n",
        "plt.scatter(X_train, y_train,c='b',label=\"Training data\") #our model will learn on this \n",
        "#plot test data in green\n",
        "plt.scatter(X_test, y_test, c='g',label=\"testing data\") #want our model to be able to predict this(given X, what's y?)\n",
        "#show a legend\n",
        "plt.legend();"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UW6emuvmuXsY"
      },
      "source": [
        "# Let's have a look at how to build a neural network for our data\n",
        "\n",
        "# 1. Create a model\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(1)                             \n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# # 3. Fit the model\n",
        "# model.fit(X_train, y_train, epochs=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCE97RBzuXvX"
      },
      "source": [
        "#model.summary()\n",
        "#ValueError: This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agDWgwkPuXzQ"
      },
      "source": [
        "# Let's create a model which builds autoatically by defining the input_shape aurgument in the first layer.\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "#1. Create a model (same as above)\n",
        "model = tf.keras.Sequential([ \n",
        "  tf.keras.layers.Dense(10,input_shape=[1],name=\"input_layer\"),\n",
        "  tf.keras.layers.Dense(1, name = \"output_layer\")\n",
        "],name=\"model_1\")\n",
        "\n",
        "#2. compile the model(same as above)\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.02),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wm6VgnGzuX1l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1aa23f5-8971-4ad1-ce64-b3456d1ba543"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_layer (Dense)          (None, 10)                20        \n",
            "_________________________________________________________________\n",
            "output_layer (Dense)         (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4sGSpgasd-y"
      },
      "source": [
        "* Total params - total number of parameters in the model.\n",
        "* Trainable parameters - these are the parameters (patterns) the model can update as it trains.\n",
        "* Non-trainable params - these parameters aren't updated during training (this is typical when you bring in already learn patterns or parameters from other models during transfer learning)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iS_sAiLDsd8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40486e6d-6c42-4647-f4bb-cbfeb1d30d17"
      },
      "source": [
        "model.fit(X_train, y_train,epochs=100,verbose=1) #verbose=0 shows no output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 24.7686 - mae: 24.7686\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 13.8862 - mae: 13.8862\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.6938 - mae: 8.6938\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.7512 - mae: 11.7512\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.3957 - mae: 12.3957\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.2640 - mae: 11.2640\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.4643 - mae: 9.4643\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.5047 - mae: 7.5047\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.8050 - mae: 7.8050\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.1223 - mae: 7.1223\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.0396 - mae: 7.0396\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.1015 - mae: 7.1015\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.5018 - mae: 6.5018\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.3082 - mae: 6.3082\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.0119 - mae: 6.0119\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.1155 - mae: 6.1155\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.7128 - mae: 5.7128\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.2442 - mae: 6.2442\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.6515 - mae: 5.6515\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.6526 - mae: 5.6526\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.2804 - mae: 5.2804\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.1428 - mae: 5.1428\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.2437 - mae: 5.2437\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.8424 - mae: 4.8424\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 4.8721 - mae: 4.8721\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 4.5600 - mae: 4.5600\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 4.6319 - mae: 4.6319\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 4.2820 - mae: 4.2820\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 4.2147 - mae: 4.2147\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 4.1282 - mae: 4.1282\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.7572 - mae: 3.7572\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.8433 - mae: 3.8433\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3.7165 - mae: 3.7165\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3.6038 - mae: 3.6038\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 3.4596 - mae: 3.4596\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.8795 - mae: 2.8795\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.4909 - mae: 3.4909\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.6218 - mae: 2.6218\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 2.8515 - mae: 2.8515\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.1578 - mae: 2.1578\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.6437 - mae: 2.6437\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.7052 - mae: 1.7052\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.8144 - mae: 1.8144\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.5629 - mae: 1.5629\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.3368 - mae: 1.3368\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.2766 - mae: 1.2766\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.4963 - mae: 0.4963\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.4977 - mae: 1.4977\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.6703 - mae: 1.6703\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.4361 - mae: 1.4361\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.0103 - mae: 2.0103\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.0801 - mae: 1.0801\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.6476 - mae: 1.6476\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.1792 - mae: 1.1792\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.7333 - mae: 1.7333\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.2911 - mae: 1.2911\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.0116 - mae: 1.0116\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.7487 - mae: 1.7487\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.7840 - mae: 0.7840\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.9121 - mae: 1.9121\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5478 - mae: 0.5478\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.5952 - mae: 2.5952\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1.3035 - mae: 1.3035\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.2842 - mae: 1.2842\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.3744 - mae: 0.3744\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.4938 - mae: 1.4938\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.7529 - mae: 0.7529\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7220 - mae: 0.7220\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.7894 - mae: 0.7894\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.2060 - mae: 1.2060\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7661 - mae: 0.7661\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.1101 - mae: 1.1101\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6584 - mae: 0.6584\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.2543 - mae: 0.2543\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.1778 - mae: 2.1778\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.8935 - mae: 0.8935\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.6666 - mae: 1.6666\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5760 - mae: 0.5760\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.6207 - mae: 1.6207\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.2009 - mae: 0.2009\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.7404 - mae: 0.7404\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.0248 - mae: 1.0248\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0503 - mae: 0.0503\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4422 - mae: 0.4422\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.1371 - mae: 1.1371\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.8457 - mae: 0.8457\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6610 - mae: 0.6610\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.0670 - mae: 1.0670\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8283 - mae: 0.8283\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.3209 - mae: 0.3209\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.2793 - mae: 0.2793\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.5169 - mae: 0.5169\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4752 - mae: 0.4752\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.1434 - mae: 0.1434\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.2661 - mae: 0.2661\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.1159 - mae: 1.1159\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6589 - mae: 0.6589\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6528 - mae: 0.6528\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.4582 - mae: 0.4582\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 1.0005 - mae: 1.0005\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbef7beaf10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwMi3SZ2sd51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "946bb923-a23f-4e88-a213-22882bbd2dc9"
      },
      "source": [
        "#get the summary of our model\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_layer (Dense)          (None, 10)                20        \n",
            "_________________________________________________________________\n",
            "output_layer (Dense)         (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6pmkikd9bOs"
      },
      "source": [
        "###using PLOT MODEL to visualise our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wUBM_Ufsd3N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "aa7fc05e-9f6e-4a7e-d96b-a024cd442c12"
      },
      "source": [
        "# another way to visualise our model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model=model,show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hi3Y500Wsdz-"
      },
      "source": [
        "### visualing our model's predictions\n",
        "\n",
        "to visualise, it is a good idea to plotthem against the ground truth\n",
        "\n",
        "often you'll see this in the form of y_test or y_true vs y_pred"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtJ8vowksdxb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "539210b1-280a-4ad2-c8f5-d20cebcbbe24"
      },
      "source": [
        "#make some predictions\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:7 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbf000b8170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 70.60006 ],\n",
              "       [ 74.63862 ],\n",
              "       [ 78.67718 ],\n",
              "       [ 82.71574 ],\n",
              "       [ 86.7543  ],\n",
              "       [ 90.79286 ],\n",
              "       [ 94.83143 ],\n",
              "       [ 98.86999 ],\n",
              "       [102.90854 ],\n",
              "       [106.947105]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqc4swuF-ysN",
        "outputId": "8a83c043-6978-4da5-eef1-dfb0958a218e"
      },
      "source": [
        "y_test #ground truth"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSKh4oYv-yvE"
      },
      "source": [
        "###In the ideal would want our model to predict exactly the ground truth values.\n",
        "\n",
        "Rather than comparing them manually one by one we can just plot a graph of the actual values of y and those predicted by our model.\n",
        "\n",
        "#Let's see how we visualise them\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5yZ1jSFAW6y"
      },
      "source": [
        "🔑 Note: If you feel like you're going to reuse some kind of functionality in the future, it's a good idea to turn it into a function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCH0d_6F-yxx"
      },
      "source": [
        "#Let's create a plotting function.\n",
        "def plot_predictions(train_data=X_train,\n",
        "                     train_labels=y_train,\n",
        "                     test_data=X_test,\n",
        "                     test_labels=y_test,\n",
        "                     predictions=y_pred):\n",
        "  \"\"\"\n",
        "  plots training data, test data and compares predictions to the ground truth labels\n",
        "  \n",
        "  \"\"\"\n",
        "  plt.figure(figsize=(10,7))\n",
        "  # plot training data in blue\n",
        "  plt.scatter(train_data,train_labels,c=\"b\",label=\"Training data\")\n",
        "  # plot test data in green\n",
        "  plt.scatter(test_data,test_labels,c=\"g\",label=\"Test data\")\n",
        "  #plot model's predictions in red\n",
        "  plt.scatter(test_data,predictions,c=\"r\",label=\"Predictions\")\n",
        "\n",
        "  #show legend\n",
        "  plt.legend(); \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "8-Yr9XEm-y0f",
        "outputId": "7ab816f1-9b83-4570-f280-5f61c6857cce"
      },
      "source": [
        "plot_predictions(train_data=X_train,\n",
        "                 train_labels=y_train,\n",
        "                 test_data=X_test,\n",
        "                 test_labels=y_test,\n",
        "                 predictions=y_pred)\n",
        "#you dont have to give the arguments, but this is just to keep it complete."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlZ-hycyCslS"
      },
      "source": [
        "* that is pretty accurate: with SGD()\n",
        "\n",
        "* with Adam(lr=0.02 AND EPOCHS EXACTLY EQUAL TO 100, IF YOU INCREASE THE EPOCHS, I.E., BY RUNNING THE MODEL MULTIPLE TIMES, IT MIGHT GET OVERFITTED, THEREFORE IN SUCH CASES JUST RESTART AND RUN ALL.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3on5PllDHRu"
      },
      "source": [
        "#but just to know how much error actually exists..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fl1Bnuj5D4yF"
      },
      "source": [
        "###Evaluating our model's predictions with regression evaluation metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSrfqBLkD400"
      },
      "source": [
        "* MEAN ABSOULTE ERROR: \n",
        " >tf.keras.losses.MAE()\n",
        " \n",
        " > \"on average, how wrong is each of my model's predictions\" \n",
        "\n",
        "(WHEN TO USE: AS A GREAT STARTER METRIC FOR ANY REGRESSION PROBLEM.)\n",
        "\n",
        "* MEAN SQUARED ERROR(MSE):\n",
        " > tf.keras.losses.MSE() \n",
        "\n",
        " > \"square the average errors.\"\n",
        "\n",
        "(WHEN TO USE: WHEN THE LARGER ERRORS ARE MORE SIGNIFICANT THAN SMALLER ERRORS.)\n",
        "\n",
        "* HUBER : tf.keras.losses.Huber()\n",
        "\n",
        "(WHEN TO USE: COMBINATION OF MSE AND MAE. LESS SENSITIVE TO OUTLIERS THAN MSE.) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wec227gsD43N",
        "outputId": "9b7f772a-4a25-42e7-cab3-5cc27bb2b820"
      },
      "source": [
        "# evaluate the model on the test set\n",
        "model.evaluate(X_test,y_test) #Returns the loss value & metrics values for the model in test mode."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 125ms/step - loss: 0.7736 - mae: 0.7736\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7735801935195923, 0.7735801935195923]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ne7YniexD450",
        "outputId": "0070447f-f820-42f4-8015-7e5cf034635e"
      },
      "source": [
        "# calculate the mean absolute error\n",
        "mae = tf.keras.losses.MAE(y_test,y_pred)\n",
        "mae"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
              "array([17.519953, 14.416829, 12.129129, 10.656853, 10.      , 10.158572,\n",
              "       11.132571, 12.921992, 15.526831, 18.947105], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ug_fJPl3D49B",
        "outputId": "7497c170-cdb9-43d3-a026-2a0ed8a71430"
      },
      "source": [
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 70.60006 ],\n",
              "       [ 74.63862 ],\n",
              "       [ 78.67718 ],\n",
              "       [ 82.71574 ],\n",
              "       [ 86.7543  ],\n",
              "       [ 90.79286 ],\n",
              "       [ 94.83143 ],\n",
              "       [ 98.86999 ],\n",
              "       [102.90854 ],\n",
              "       [106.947105]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zePco3kyD4_9"
      },
      "source": [
        "#this is in an array format, let's make it a tensor."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avfhFAVd1u4E",
        "outputId": "10c4299a-f6f9-421f-bd15-bceb31b7e771"
      },
      "source": [
        "X_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([60, 64, 68, 72, 76, 80, 84, 88, 92, 96], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuz8E-5nD5CQ",
        "outputId": "c9453dca-07fd-4f04-c9f6-98c43727113e"
      },
      "source": [
        "tf.constant(y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
              "array([[ 70.60006 ],\n",
              "       [ 74.63862 ],\n",
              "       [ 78.67718 ],\n",
              "       [ 82.71574 ],\n",
              "       [ 86.7543  ],\n",
              "       [ 90.79286 ],\n",
              "       [ 94.83143 ],\n",
              "       [ 98.86999 ],\n",
              "       [102.90854 ],\n",
              "       [106.947105]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaYELmQKNA10",
        "outputId": "637bac80-bcb7-4759-b585-94d17c89c2ac"
      },
      "source": [
        "#now,\n",
        "y_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8gKf813NEIk"
      },
      "source": [
        "#their shapes DON'T match and for error calculation, they must.\n",
        "#therefor, we need to reshape the y_pred tensor."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jd2_NDoQNPq4",
        "outputId": "cfbead98-dc9f-4cc5-f5e1-08417e5c92bc"
      },
      "source": [
        "tf.squeeze(y_pred) #doing this will get rid of the extra 1 dimension."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
              "array([ 70.60006 ,  74.63862 ,  78.67718 ,  82.71574 ,  86.7543  ,\n",
              "        90.79286 ,  94.83143 ,  98.86999 , 102.90854 , 106.947105],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aS8S7NhTNTGs"
      },
      "source": [
        "#now, both the tensors are of the same shape."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MddfF7CnNefc",
        "outputId": "c2566d30-5550-422c-9d6a-8c5931c42658"
      },
      "source": [
        "mae = tf.keras.losses.MAE(y_test,tf.squeeze(y_pred))\n",
        "mae\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.7735817>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rviSqm3YNgAH"
      },
      "source": [
        "#yay!! \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6mbfoD-NgDC"
      },
      "source": [
        "### NOW, let's calculate the MSE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riob2haHNgGC",
        "outputId": "0a294527-97b2-4731-d3f1-1c2018d9a7f9"
      },
      "source": [
        "mse = tf.keras.losses.MSE(y_test,tf.squeeze(y_pred))\n",
        "mse"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.61069584>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PrJeHLyNgIV"
      },
      "source": [
        "# the error is large because, obviously it is squared."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tixowIFYNgLS"
      },
      "source": [
        "###HUBER:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9DQMVy3NgNY"
      },
      "source": [
        "#huber = tf.keras.losses.Huber(y_test,tf.cast(tf.squeeze(y_pred),dtype=tf.float32))\n",
        "#huber"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FMq_-QdNgP4"
      },
      "source": [
        "#make some functions to reuse MAE and MSE\n",
        "def mae(y_true, y_pred):\n",
        "  return tf.keras.losses.MAE(y_true=y_true,\n",
        "                             y_pred=tf.squeeze(y_pred))\n",
        "  \n",
        "def mse(y_true,y_pred):\n",
        "  return tf.keras.losses.MSE(y_true=y_true,\n",
        "                             y_pred=tf.squeeze(y_pred))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4Fap6_rNgS5",
        "outputId": "3ad8e8bd-56c6-4375-ea25-f307a8244e83"
      },
      "source": [
        "mse(y_test,tf.squeeze(y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.61069584>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yg0MacAkQ-o-",
        "outputId": "7f863670-b143-478b-96ef-e6c7fc8e8377"
      },
      "source": [
        "mae(y_test,tf.squeeze(y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.7735817>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOCBRZe-RGLL"
      },
      "source": [
        "###Running experiments to improve our model\n",
        "---\n",
        "\n",
        "Build a model -> fit it -> evaluate it ->tweak it -> fit it -> evaluate it ->tweak it -> fit it -> evaluate it ...\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "1. Get more data - get more examples for your model to train on (more opportunities to learn patterns or relationships between features and labels).\n",
        "2. Make your model larger (using a more complex model) - this might come in the form of more layers or more hidden units in each layer.\n",
        "3. Train for longer - give your model of a chance to find patterns in the data.\n",
        "\n",
        "Let's do 3 modelling experiments:\n",
        " 1. 'model_1'  - same as the original, 1 layer, trained for 100 epochs\n",
        " 2. 'model_2' - 2 layers, 100 epochs\n",
        " 3. 'model_3' - 2 layers, 500 epochs\n",
        "\n",
        " **BUILD MODEL_1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8TjEpnCW7is",
        "outputId": "27204fa5-0a73-4010-cf1e-537edf5791e5"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "#1. Create the model\n",
        "model_1 = tf.keras.Sequential(\n",
        "    [\n",
        "     tf.keras.layers.Dense(1)\n",
        "    ])\n",
        "\n",
        "#2. compile the model\n",
        "model_1.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "#3. fit the model\n",
        "model_1.fit(X_train,y_train,epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 16.4124 - mae: 16.4124\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.0829 - mae: 11.0829\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.1242 - mae: 11.1242\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.6945 - mae: 8.6945\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.8003 - mae: 9.8003\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.5263 - mae: 9.5263\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.4102 - mae: 8.4102\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.1449 - mae: 9.1449\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 19.4932 - mae: 19.4932\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.6061 - mae: 9.6061\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.5992 - mae: 8.5992\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.9324 - mae: 10.9324\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.0574 - mae: 10.0574\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 16.5679 - mae: 16.5679\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.4537 - mae: 11.4537\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.4056 - mae: 8.4056\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 13.8417 - mae: 13.8417\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.6621 - mae: 11.6621\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 18.7623 - mae: 18.7623\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 15.5702 - mae: 15.5702\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.9959 - mae: 10.9959\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.0023 - mae: 8.0023\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.8593 - mae: 9.8593\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.5796 - mae: 7.5796\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.7226 - mae: 13.7226\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 17.1740 - mae: 17.1740\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.4233 - mae: 13.4233\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 14.5473 - mae: 14.5473\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.8753 - mae: 9.8753\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.1187 - mae: 17.1187\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 24.5949 - mae: 24.5949\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.6765 - mae: 7.6765\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.2971 - mae: 9.2971\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.1703 - mae: 14.1703\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.8635 - mae: 10.8635\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 13.5689 - mae: 13.5689\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.3448 - mae: 9.3448\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.4804 - mae: 10.4804\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.0178 - mae: 10.0178\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.8005 - mae: 10.8005\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.7789 - mae: 7.7789\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.2844 - mae: 10.2844\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.9628 - mae: 8.9628\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.6243 - mae: 12.6243\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 14.1236 - mae: 14.1236\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.2681 - mae: 8.2681\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.0126 - mae: 9.0126\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.6882 - mae: 10.6882\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.7431 - mae: 7.7431\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.3950 - mae: 9.3950\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.9267 - mae: 8.9267\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 16.9818 - mae: 16.9818\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 14.8677 - mae: 14.8677\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 22.0413 - mae: 22.0413\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 17.0640 - mae: 17.0640\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.9520 - mae: 9.9520\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.7522 - mae: 9.7522\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.4378 - mae: 9.4378\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.3373 - mae: 8.3373\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.6425 - mae: 9.6425\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.7590 - mae: 11.7590\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.7187 - mae: 11.7187\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 7.2316 - mae: 7.2316\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 17.7848 - mae: 17.7848\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.6255 - mae: 12.6255\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.2840 - mae: 13.2840\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.8471 - mae: 7.8471\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.9708 - mae: 9.9708\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.4903 - mae: 12.4903\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.5001 - mae: 8.5001\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.9996 - mae: 9.9996\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.1797 - mae: 10.1797\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 13.0024 - mae: 13.0024\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.3812 - mae: 10.3812\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.7621 - mae: 9.7621\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.5186 - mae: 11.5186\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.3070 - mae: 8.3070\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.4436 - mae: 9.4436\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 20.3897 - mae: 20.3897\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 15.4751 - mae: 15.4751\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.0208 - mae: 9.0208\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.3869 - mae: 13.3869\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.9649 - mae: 7.9649\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.5702 - mae: 7.5702\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.9706 - mae: 9.9706\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.0533 - mae: 9.0533\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.2670 - mae: 12.2670\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.6052 - mae: 10.6052\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.1986 - mae: 7.1986\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.0379 - mae: 13.0379\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.1968 - mae: 7.1968\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.5386 - mae: 7.5386\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.0932 - mae: 7.0932\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.8860 - mae: 12.8860\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.9620 - mae: 9.9620\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.7739 - mae: 8.7739\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 13.0861 - mae: 13.0861\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.3848 - mae: 8.3848\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.7828 - mae: 9.7828\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.5252 - mae: 8.5252\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbefff19410>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "yJso7r-iZCqs",
        "outputId": "444d863a-29de-4ed4-a54e-bec65a686f94"
      },
      "source": [
        "# make and plot predictions\n",
        "y_preds_1 = model_1.predict(X_test)\n",
        "\n",
        "plot_predictions(predictions=y_preds_1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:8 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbefff114d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AG_xwh-eZ3t1"
      },
      "source": [
        "#that is quite a large diffence, let's calculate the error evaluation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t535-QcsZ_kB",
        "outputId": "4f08c796-a966-4b2a-cb09-923c6682b668"
      },
      "source": [
        "mae_1 = mae (y_test, y_preds_1)\n",
        "mse_1 = mse(y_test,y_preds_1)\n",
        "mae_1, mse_1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(), dtype=float32, numpy=18.745327>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=353.57336>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtZZW1cuawM3"
      },
      "source": [
        "**Build model_2**\n",
        "\n",
        "* 2 dense layers, epochs =100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBCdojGIcJrq",
        "outputId": "9547420f-4542-4525-bdb4-3126d43bd7ae"
      },
      "source": [
        "# set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "#1. create the model\n",
        "model_2 = tf.keras.Sequential(\n",
        "    [\n",
        "     tf.keras.layers.Dense(10),\n",
        "     tf.keras.layers.Dense(1)])\n",
        "     \n",
        "\n",
        "#compile the model\n",
        "model_2.compile(loss=tf.keras.losses.mae,\n",
        "                optimizer=tf.keras.optimizers.SGD(),\n",
        "                metrics=[\"mse\"])\n",
        "\n",
        "#fit the model\n",
        "model_2.fit(X_train, y_train, epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 26.8627 - mse: 1015.8976\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 24.4175 - mse: 767.5334\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 31.5187 - mse: 1433.3081\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 27.8490 - mse: 1141.6671\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 14.6465 - mse: 267.4541\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.9682 - mse: 169.5529\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.0874 - mse: 141.6589\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.3978 - mse: 167.3422\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 42.4087 - mse: 2772.5432\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 28.3537 - mse: 1129.8181\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.6590 - mse: 132.9751\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 25.8820 - mse: 933.4347\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 16.7682 - mse: 398.1734\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 26.6019 - mse: 1102.2358\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 17.7361 - mse: 441.0350\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.4550 - mse: 81.2729\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 10.6974 - mse: 163.8851\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 20.7691 - mse: 610.4133\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.6535 - mse: 146.6566\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 18.4600 - mse: 487.0986\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 16.2352 - mse: 362.8490\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.5012 - mse: 290.6680\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 8.6493 - mse: 88.0710\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.4430 - mse: 131.0228\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.8060 - mse: 237.9437\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 26.8011 - mse: 1075.4349\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.0333 - mse: 202.1001\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 23.4573 - mse: 871.2026\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.1266 - mse: 92.4710\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 31.1804 - mse: 1657.8954\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 56.8211 - mse: 5441.4578\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.2909 - mse: 221.1293\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 15.3304 - mse: 330.0120\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.8145 - mse: 215.9797\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.4721 - mse: 95.5154\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 16.6526 - mse: 404.8040\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.4634 - mse: 169.1310\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 18.7760 - mse: 459.8314\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 20.1198 - mse: 569.0893\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 21.4944 - mse: 654.6215\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.5667 - mse: 268.1430\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.2999 - mse: 188.8544\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.1115 - mse: 175.7055\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 23.5895 - mse: 869.7923\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.9461 - mse: 113.3929\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.0273 - mse: 188.4640\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.0557 - mse: 132.7936\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 17.8711 - mse: 427.6238\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.5485 - mse: 96.8224\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 13.7912 - mse: 256.8746\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.2969 - mse: 145.4000\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 32.1753 - mse: 1732.7588\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 14.1257 - mse: 300.5092\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 24.3921 - mse: 897.0253\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 23.5967 - mse: 834.7571\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.0101 - mse: 137.5419\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.4333 - mse: 186.3946\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.4491 - mse: 96.3009\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 12.6438 - mse: 218.5184\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.3168 - mse: 208.3239\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.1832 - mse: 422.8597\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 10.4860 - mse: 128.6800\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.8072 - mse: 160.7222\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 25.2892 - mse: 945.1685\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.7923 - mse: 145.3387\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 22.0328 - mse: 725.3462\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.6505 - mse: 132.1476\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.8455 - mse: 155.3464\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 23.0960 - mse: 770.1602\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.7402 - mse: 139.4087\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 15.8968 - mse: 339.6098\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 6.7092 - mse: 66.6670\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.6475 - mse: 146.9912\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 24.6152 - mse: 948.2740\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 8.7602 - mse: 119.7264\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.9799 - mse: 172.5533\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 16.6488 - mse: 432.3298\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.2784 - mse: 98.6556\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 24.4604 - mse: 902.0727\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 27.4405 - mse: 1158.6084\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.7139 - mse: 170.4368\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.6757 - mse: 196.1245\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 17.9045 - mse: 414.3998\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.0376 - mse: 70.0240\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 15.1558 - mse: 321.1297\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 15.1583 - mse: 311.4818\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 19.8683 - mse: 554.4750\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 30.7657 - mse: 1357.5454\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.7059 - mse: 108.4962\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 21.5531 - mse: 674.2966\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 9.5827 - mse: 128.0419\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 18.2158 - mse: 463.7713\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.1935 - mse: 75.5075\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.4261 - mse: 438.1330\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.1722 - mse: 164.3355\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 18.9207 - mse: 491.7021\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.2012 - mse: 208.9877\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11.2931 - mse: 158.5947\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 13.4562 - mse: 254.5623\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 20.1754 - mse: 612.1691\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbeffe34690>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzAUxFaGcJpJ",
        "outputId": "54305ee6-53e7-4db1-ac77-d0cead2263b5"
      },
      "source": [
        "#make plots and predictions\n",
        "y_preds_2 = model_2.predict(X_test)\n",
        "y_preds_2, y_test\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:9 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbf00a059e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[ 70.55218 ],\n",
              "        [ 75.13991 ],\n",
              "        [ 79.72763 ],\n",
              "        [ 84.31535 ],\n",
              "        [ 88.903076],\n",
              "        [ 93.49081 ],\n",
              "        [ 98.07853 ],\n",
              "        [102.66625 ],\n",
              "        [107.253975],\n",
              "        [111.8417  ]], dtype=float32),\n",
              " <tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "jlCCIeEI2Xkp",
        "outputId": "27b470dc-df3d-46fe-c08f-15d5a0c10465"
      },
      "source": [
        "plot_predictions(predictions=y_preds_2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hw8tMuhjcJnU",
        "outputId": "0adc1930-4fbb-48d1-c933-96706beb3a0a"
      },
      "source": [
        "# calculate model_2 evaluation matrices:\n",
        "mae_2 = mae(y_test, y_preds_2)\n",
        "mse_2 = mse(y_test, y_preds_2)\n",
        "mae_2,mse_2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(), dtype=float32, numpy=3.1969407>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=13.070143>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQGt4zzucJlD"
      },
      "source": [
        "**Build model_3**\n",
        "same as model_2, but epochs=500"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdWzmP8HcJib",
        "outputId": "c62c31cb-edf0-4ad0-abf1-e4539bf56424"
      },
      "source": [
        "  # set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "#1. create the model\n",
        "model_3 = tf.keras.Sequential(\n",
        "    [\n",
        "     tf.keras.layers.Dense(10),\n",
        "     tf.keras.layers.Dense(1)])\n",
        "\n",
        "\n",
        "#compile the model\n",
        "model_3.compile(loss=tf.keras.losses.mae,\n",
        "                optimizer=tf.keras.optimizers.SGD(),\n",
        "                metrics=[\"mse\"])\n",
        "\n",
        "#fit the model\n",
        "model_3.fit(X_train, y_train, epochs=500)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 26.8627 - mse: 1015.8976\n",
            "Epoch 2/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 24.4175 - mse: 767.5334\n",
            "Epoch 3/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 31.5187 - mse: 1433.3081\n",
            "Epoch 4/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 27.8490 - mse: 1141.6671\n",
            "Epoch 5/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.6465 - mse: 267.4541\n",
            "Epoch 6/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.9682 - mse: 169.5529\n",
            "Epoch 7/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.0874 - mse: 141.6589\n",
            "Epoch 8/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.3978 - mse: 167.3422\n",
            "Epoch 9/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 42.4087 - mse: 2772.5432\n",
            "Epoch 10/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 28.3537 - mse: 1129.8181\n",
            "Epoch 11/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.6590 - mse: 132.9751\n",
            "Epoch 12/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 25.8820 - mse: 933.4347\n",
            "Epoch 13/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 16.7682 - mse: 398.1734\n",
            "Epoch 14/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 26.6019 - mse: 1102.2358\n",
            "Epoch 15/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 17.7361 - mse: 441.0350\n",
            "Epoch 16/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.4550 - mse: 81.2729\n",
            "Epoch 17/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.6974 - mse: 163.8851\n",
            "Epoch 18/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 20.7691 - mse: 610.4133\n",
            "Epoch 19/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.6535 - mse: 146.6566\n",
            "Epoch 20/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 18.4600 - mse: 487.0986\n",
            "Epoch 21/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 16.2352 - mse: 362.8490\n",
            "Epoch 22/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 14.5012 - mse: 290.6680\n",
            "Epoch 23/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.6493 - mse: 88.0710\n",
            "Epoch 24/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.4430 - mse: 131.0228\n",
            "Epoch 25/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 12.8060 - mse: 237.9437\n",
            "Epoch 26/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 26.8011 - mse: 1075.4349\n",
            "Epoch 27/500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 12.0333 - mse: 202.1001\n",
            "Epoch 28/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 23.4573 - mse: 871.2026\n",
            "Epoch 29/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.1266 - mse: 92.4710\n",
            "Epoch 30/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 31.1804 - mse: 1657.8954\n",
            "Epoch 31/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 56.8211 - mse: 5441.4578\n",
            "Epoch 32/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.2909 - mse: 221.1293\n",
            "Epoch 33/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 15.3304 - mse: 330.0120\n",
            "Epoch 34/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 12.8145 - mse: 215.9797\n",
            "Epoch 35/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.4721 - mse: 95.5154\n",
            "Epoch 36/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 16.6526 - mse: 404.8040\n",
            "Epoch 37/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.4634 - mse: 169.1310\n",
            "Epoch 38/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 18.7760 - mse: 459.8314\n",
            "Epoch 39/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 20.1198 - mse: 569.0893\n",
            "Epoch 40/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 21.4944 - mse: 654.6215\n",
            "Epoch 41/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.5667 - mse: 268.1430\n",
            "Epoch 42/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.2999 - mse: 188.8544\n",
            "Epoch 43/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.1115 - mse: 175.7055\n",
            "Epoch 44/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 23.5895 - mse: 869.7923\n",
            "Epoch 45/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 9.9461 - mse: 113.3929\n",
            "Epoch 46/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.0273 - mse: 188.4640\n",
            "Epoch 47/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.0557 - mse: 132.7936\n",
            "Epoch 48/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 17.8711 - mse: 427.6238\n",
            "Epoch 49/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.5485 - mse: 96.8224\n",
            "Epoch 50/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.7912 - mse: 256.8746\n",
            "Epoch 51/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.2969 - mse: 145.4000\n",
            "Epoch 52/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 32.1753 - mse: 1732.7588\n",
            "Epoch 53/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 14.1257 - mse: 300.5092\n",
            "Epoch 54/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 24.3921 - mse: 897.0253\n",
            "Epoch 55/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 23.5967 - mse: 834.7571\n",
            "Epoch 56/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.0101 - mse: 137.5419\n",
            "Epoch 57/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.4333 - mse: 186.3946\n",
            "Epoch 58/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.4491 - mse: 96.3009\n",
            "Epoch 59/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.6438 - mse: 218.5184\n",
            "Epoch 60/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.3168 - mse: 208.3239\n",
            "Epoch 61/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.1832 - mse: 422.8597\n",
            "Epoch 62/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.4860 - mse: 128.6800\n",
            "Epoch 63/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.8072 - mse: 160.7222\n",
            "Epoch 64/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 25.2892 - mse: 945.1685\n",
            "Epoch 65/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.7923 - mse: 145.3387\n",
            "Epoch 66/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 22.0328 - mse: 725.3462\n",
            "Epoch 67/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.6505 - mse: 132.1476\n",
            "Epoch 68/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.8455 - mse: 155.3464\n",
            "Epoch 69/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 23.0960 - mse: 770.1602\n",
            "Epoch 70/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.7402 - mse: 139.4087\n",
            "Epoch 71/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 15.8968 - mse: 339.6098\n",
            "Epoch 72/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 6.7092 - mse: 66.6670\n",
            "Epoch 73/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.6475 - mse: 146.9912\n",
            "Epoch 74/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 24.6152 - mse: 948.2740\n",
            "Epoch 75/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.7602 - mse: 119.7264\n",
            "Epoch 76/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 11.9799 - mse: 172.5533\n",
            "Epoch 77/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 16.6488 - mse: 432.3298\n",
            "Epoch 78/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.2784 - mse: 98.6556\n",
            "Epoch 79/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 24.4604 - mse: 902.0727\n",
            "Epoch 80/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 27.4405 - mse: 1158.6084\n",
            "Epoch 81/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.7139 - mse: 170.4368\n",
            "Epoch 82/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.6757 - mse: 196.1245\n",
            "Epoch 83/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.9045 - mse: 414.3998\n",
            "Epoch 84/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.0376 - mse: 70.0240\n",
            "Epoch 85/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 15.1558 - mse: 321.1297\n",
            "Epoch 86/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 15.1583 - mse: 311.4818\n",
            "Epoch 87/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 19.8683 - mse: 554.4750\n",
            "Epoch 88/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 30.7657 - mse: 1357.5454\n",
            "Epoch 89/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.7059 - mse: 108.4962\n",
            "Epoch 90/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 21.5531 - mse: 674.2966\n",
            "Epoch 91/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.5827 - mse: 128.0419\n",
            "Epoch 92/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 18.2158 - mse: 463.7713\n",
            "Epoch 93/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.1935 - mse: 75.5075\n",
            "Epoch 94/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.4261 - mse: 438.1330\n",
            "Epoch 95/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.1722 - mse: 164.3355\n",
            "Epoch 96/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 18.9207 - mse: 491.7021\n",
            "Epoch 97/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 12.2012 - mse: 208.9877\n",
            "Epoch 98/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.2931 - mse: 158.5947\n",
            "Epoch 99/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.4562 - mse: 254.5623\n",
            "Epoch 100/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 20.1754 - mse: 612.1691\n",
            "Epoch 101/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.4395 - mse: 176.8360\n",
            "Epoch 102/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 17.0888 - mse: 409.9835\n",
            "Epoch 103/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 6.9455 - mse: 65.4455\n",
            "Epoch 104/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 24.3779 - mse: 798.6034\n",
            "Epoch 105/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.8800 - mse: 438.3793\n",
            "Epoch 106/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.5557 - mse: 121.1321\n",
            "Epoch 107/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 26.5426 - mse: 997.9331\n",
            "Epoch 108/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.2375 - mse: 262.9666\n",
            "Epoch 109/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.1284 - mse: 95.7257\n",
            "Epoch 110/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.9256 - mse: 105.0342\n",
            "Epoch 111/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 14.0550 - mse: 272.6900\n",
            "Epoch 112/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.7418 - mse: 125.6841\n",
            "Epoch 113/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 17.5151 - mse: 450.2865\n",
            "Epoch 114/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 17.0304 - mse: 440.4950\n",
            "Epoch 115/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.9228 - mse: 149.7184\n",
            "Epoch 116/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 23.5453 - mse: 811.6179\n",
            "Epoch 117/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.8340 - mse: 102.5076\n",
            "Epoch 118/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.2978 - mse: 126.2972\n",
            "Epoch 119/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.3192 - mse: 82.1770\n",
            "Epoch 120/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 30.7265 - mse: 1389.9014\n",
            "Epoch 121/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.1436 - mse: 70.3915\n",
            "Epoch 122/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 29.4327 - mse: 1314.3137\n",
            "Epoch 123/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 34.2183 - mse: 1694.8665\n",
            "Epoch 124/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 19.6697 - mse: 576.5111\n",
            "Epoch 125/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 6.5959 - mse: 64.4558\n",
            "Epoch 126/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 21.8683 - mse: 680.1274\n",
            "Epoch 127/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.0892 - mse: 69.8523\n",
            "Epoch 128/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 21.1329 - mse: 666.8413\n",
            "Epoch 129/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.3481 - mse: 128.1660\n",
            "Epoch 130/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 24.2633 - mse: 837.1738\n",
            "Epoch 131/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.9302 - mse: 137.6920\n",
            "Epoch 132/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 18.3634 - mse: 505.2126\n",
            "Epoch 133/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.2677 - mse: 72.3204\n",
            "Epoch 134/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 18.4166 - mse: 502.4972\n",
            "Epoch 135/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.7401 - mse: 121.3270\n",
            "Epoch 136/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.8516 - mse: 461.5897\n",
            "Epoch 137/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 22.9936 - mse: 723.8245\n",
            "Epoch 138/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 8.2013 - mse: 108.2334\n",
            "Epoch 139/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.0097 - mse: 112.3626\n",
            "Epoch 140/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 15.9624 - mse: 368.3736\n",
            "Epoch 141/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.6422 - mse: 95.7451\n",
            "Epoch 142/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 39.2127 - mse: 2592.6741\n",
            "Epoch 143/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 25.9599 - mse: 959.6395\n",
            "Epoch 144/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.6134 - mse: 117.2102\n",
            "Epoch 145/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 27.7680 - mse: 1011.4874\n",
            "Epoch 146/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.3428 - mse: 92.0141\n",
            "Epoch 147/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 15.0730 - mse: 289.3356\n",
            "Epoch 148/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 19.1933 - mse: 498.5642\n",
            "Epoch 149/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.4993 - mse: 85.9696\n",
            "Epoch 150/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.4097 - mse: 62.0831\n",
            "Epoch 151/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 18.1762 - mse: 483.9472\n",
            "Epoch 152/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.9065 - mse: 119.1116\n",
            "Epoch 153/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 30.6868 - mse: 1345.6315\n",
            "Epoch 154/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.6497 - mse: 162.7593\n",
            "Epoch 155/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.0886 - mse: 371.0081\n",
            "Epoch 156/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 18.0462 - mse: 472.6204\n",
            "Epoch 157/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 34.4868 - mse: 1870.8902\n",
            "Epoch 158/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.3002 - mse: 135.3050\n",
            "Epoch 159/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.5288 - mse: 85.5955\n",
            "Epoch 160/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 22.2562 - mse: 726.2963\n",
            "Epoch 161/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.2986 - mse: 186.9199\n",
            "Epoch 162/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 21.5576 - mse: 681.2422\n",
            "Epoch 163/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 18.8924 - mse: 524.9752\n",
            "Epoch 164/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.9458 - mse: 171.1847\n",
            "Epoch 165/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.7489 - mse: 143.2768\n",
            "Epoch 166/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 22.6552 - mse: 731.0229\n",
            "Epoch 167/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 26.9724 - mse: 1095.2429\n",
            "Epoch 168/500\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 9.2709 - mse: 101.7484\n",
            "Epoch 169/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 23.1678 - mse: 821.7977\n",
            "Epoch 170/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.3051 - mse: 158.1281\n",
            "Epoch 171/500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 18.9237 - mse: 538.3760\n",
            "Epoch 172/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 29.9900 - mse: 1388.8494\n",
            "Epoch 173/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 16.4918 - mse: 424.2662\n",
            "Epoch 174/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.2796 - mse: 165.7304\n",
            "Epoch 175/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 28.8074 - mse: 1166.1734\n",
            "Epoch 176/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 8.1042 - mse: 72.2274\n",
            "Epoch 177/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.8722 - mse: 95.6579\n",
            "Epoch 178/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.8721 - mse: 455.3681\n",
            "Epoch 179/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.4428 - mse: 144.1929\n",
            "Epoch 180/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.2716 - mse: 82.2663\n",
            "Epoch 181/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 17.0166 - mse: 425.9957\n",
            "Epoch 182/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.3910 - mse: 136.5952\n",
            "Epoch 183/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.1568 - mse: 188.0895\n",
            "Epoch 184/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 31.6483 - mse: 1471.7637\n",
            "Epoch 185/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.0154 - mse: 83.6483\n",
            "Epoch 186/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 16.6843 - mse: 393.0200\n",
            "Epoch 187/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.1126 - mse: 74.4118\n",
            "Epoch 188/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 29.6995 - mse: 1242.6110\n",
            "Epoch 189/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.3776 - mse: 231.8943\n",
            "Epoch 190/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 19.3024 - mse: 551.6450\n",
            "Epoch 191/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.9023 - mse: 267.3248\n",
            "Epoch 192/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.9345 - mse: 231.6658\n",
            "Epoch 193/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 29.5007 - mse: 1194.6764\n",
            "Epoch 194/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 6.6526 - mse: 65.7294\n",
            "Epoch 195/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.6620 - mse: 66.1468\n",
            "Epoch 196/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 22.8540 - mse: 756.0894\n",
            "Epoch 197/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 20.7492 - mse: 647.7006\n",
            "Epoch 198/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.8978 - mse: 216.4666\n",
            "Epoch 199/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 17.4222 - mse: 443.4027\n",
            "Epoch 200/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.4876 - mse: 273.2731\n",
            "Epoch 201/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.6035 - mse: 42.9682\n",
            "Epoch 202/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.1062 - mse: 266.1792\n",
            "Epoch 203/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 8.4001 - mse: 107.1470\n",
            "Epoch 204/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 21.0158 - mse: 659.9834\n",
            "Epoch 205/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.7459 - mse: 102.3799\n",
            "Epoch 206/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11.0638 - mse: 173.5503\n",
            "Epoch 207/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 13.8665 - mse: 299.2529\n",
            "Epoch 208/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.9839 - mse: 287.6854\n",
            "Epoch 209/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 14.2824 - mse: 315.9997\n",
            "Epoch 210/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 17.6257 - mse: 457.9839\n",
            "Epoch 211/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 8.8540 - mse: 113.1053\n",
            "Epoch 212/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 18.6211 - mse: 514.6912\n",
            "Epoch 213/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 15.0631 - mse: 306.5317\n",
            "Epoch 214/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 14.8075 - mse: 302.0721\n",
            "Epoch 215/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 24.6706 - mse: 859.6855\n",
            "Epoch 216/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.8053 - mse: 254.6141\n",
            "Epoch 217/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.7938 - mse: 130.2804\n",
            "Epoch 218/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.3979 - mse: 199.8039\n",
            "Epoch 219/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 5.0245 - mse: 38.1418\n",
            "Epoch 220/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.8297 - mse: 52.0833\n",
            "Epoch 221/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 37.3270 - mse: 2268.0113\n",
            "Epoch 222/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 36.7870 - mse: 2109.8339\n",
            "Epoch 223/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.3082 - mse: 96.5411\n",
            "Epoch 224/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 15.3583 - mse: 341.1677\n",
            "Epoch 225/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 16.9646 - mse: 371.1065\n",
            "Epoch 226/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.5040 - mse: 392.6132\n",
            "Epoch 227/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 16.8008 - mse: 391.0562\n",
            "Epoch 228/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.3646 - mse: 293.7560\n",
            "Epoch 229/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 18.9498 - mse: 490.9765\n",
            "Epoch 230/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 15.3734 - mse: 306.9251\n",
            "Epoch 231/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 22.2855 - mse: 719.0516\n",
            "Epoch 232/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 25.6766 - mse: 944.8824\n",
            "Epoch 233/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 15.8456 - mse: 369.0504\n",
            "Epoch 234/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.1198 - mse: 60.0878\n",
            "Epoch 235/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 16.5359 - mse: 388.7437\n",
            "Epoch 236/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.8411 - mse: 59.6960\n",
            "Epoch 237/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.4978 - mse: 96.4145\n",
            "Epoch 238/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.6219 - mse: 72.8125\n",
            "Epoch 239/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 16.6738 - mse: 421.4189\n",
            "Epoch 240/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.1090 - mse: 86.4690\n",
            "Epoch 241/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.2173 - mse: 231.1879\n",
            "Epoch 242/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 8.4286 - mse: 92.9322\n",
            "Epoch 243/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 19.0474 - mse: 549.0843\n",
            "Epoch 244/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.8906 - mse: 265.0233\n",
            "Epoch 245/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.9766 - mse: 299.4019\n",
            "Epoch 246/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 16.5221 - mse: 397.0684\n",
            "Epoch 247/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 18.3671 - mse: 447.2058\n",
            "Epoch 248/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.7968 - mse: 229.7064\n",
            "Epoch 249/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.6663 - mse: 294.8631\n",
            "Epoch 250/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 24.6626 - mse: 854.8040\n",
            "Epoch 251/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.8291 - mse: 108.9488\n",
            "Epoch 252/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 38.5683 - mse: 2359.3725\n",
            "Epoch 253/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 21.8404 - mse: 672.8246\n",
            "Epoch 254/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 6.6485 - mse: 63.1855\n",
            "Epoch 255/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 24.9959 - mse: 916.8845\n",
            "Epoch 256/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.5965 - mse: 192.6703\n",
            "Epoch 257/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 10.0635 - mse: 146.8584\n",
            "Epoch 258/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 13.8021 - mse: 294.2247\n",
            "Epoch 259/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.3765 - mse: 93.9123\n",
            "Epoch 260/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 45.7482 - mse: 3211.3014\n",
            "Epoch 261/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 18.1356 - mse: 481.2484\n",
            "Epoch 262/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 6.3169 - mse: 76.1663\n",
            "Epoch 263/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 13.7268 - mse: 266.9442\n",
            "Epoch 264/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 22.1387 - mse: 702.6458\n",
            "Epoch 265/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 19.3151 - mse: 542.9797\n",
            "Epoch 266/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 10.9408 - mse: 198.3716\n",
            "Epoch 267/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 6.7507 - mse: 87.7474\n",
            "Epoch 268/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 22.1636 - mse: 703.7159\n",
            "Epoch 269/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 34.7302 - mse: 1763.6683\n",
            "Epoch 270/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.6729 - mse: 133.4597\n",
            "Epoch 271/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.5267 - mse: 226.7082\n",
            "Epoch 272/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 26.9760 - mse: 993.8127\n",
            "Epoch 273/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.6137 - mse: 205.5132\n",
            "Epoch 274/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.0721 - mse: 228.8875\n",
            "Epoch 275/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 30.5160 - mse: 1306.4889\n",
            "Epoch 276/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.5488 - mse: 82.0313\n",
            "Epoch 277/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 31.9636 - mse: 1431.5897\n",
            "Epoch 278/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.5564 - mse: 201.5984\n",
            "Epoch 279/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 17.3607 - mse: 449.4666\n",
            "Epoch 280/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 23.1189 - mse: 769.8318\n",
            "Epoch 281/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 22.5078 - mse: 765.5773\n",
            "Epoch 282/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.2141 - mse: 73.0942\n",
            "Epoch 283/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.7725 - mse: 78.0881\n",
            "Epoch 284/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 25.4832 - mse: 975.6879\n",
            "Epoch 285/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 13.3877 - mse: 287.5977\n",
            "Epoch 286/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.2528 - mse: 66.1270\n",
            "Epoch 287/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 25.2020 - mse: 906.1856\n",
            "Epoch 288/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 20.5697 - mse: 623.3725\n",
            "Epoch 289/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.0906 - mse: 201.3730\n",
            "Epoch 290/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 17.0029 - mse: 383.5456\n",
            "Epoch 291/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 17.6342 - mse: 443.9534\n",
            "Epoch 292/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.1010 - mse: 156.3201\n",
            "Epoch 293/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 15.5974 - mse: 331.2615\n",
            "Epoch 294/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 24.0056 - mse: 838.9369\n",
            "Epoch 295/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 17.6288 - mse: 452.2897\n",
            "Epoch 296/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 5.7207 - mse: 48.1339\n",
            "Epoch 297/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.5090 - mse: 189.7956\n",
            "Epoch 298/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 24.2070 - mse: 839.7042\n",
            "Epoch 299/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 17.5093 - mse: 463.5408\n",
            "Epoch 300/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 6.9937 - mse: 65.4162\n",
            "Epoch 301/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 25.4316 - mse: 925.3384\n",
            "Epoch 302/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 8.5327 - mse: 105.6703\n",
            "Epoch 303/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 17.2889 - mse: 446.9324\n",
            "Epoch 304/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 10.1101 - mse: 144.8192\n",
            "Epoch 305/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.0683 - mse: 234.0961\n",
            "Epoch 306/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.9177 - mse: 81.6533\n",
            "Epoch 307/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.7052 - mse: 245.0772\n",
            "Epoch 308/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.9439 - mse: 64.3301\n",
            "Epoch 309/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.8822 - mse: 120.5234\n",
            "Epoch 310/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.3575 - mse: 178.3940\n",
            "Epoch 311/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.4583 - mse: 222.8906\n",
            "Epoch 312/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 30.1003 - mse: 1268.4940\n",
            "Epoch 313/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.8146 - mse: 78.6331\n",
            "Epoch 314/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.5820 - mse: 176.5197\n",
            "Epoch 315/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 24.8169 - mse: 873.6630\n",
            "Epoch 316/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 15.7743 - mse: 381.3678\n",
            "Epoch 317/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 20.6639 - mse: 588.6182\n",
            "Epoch 318/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.6411 - mse: 75.6582\n",
            "Epoch 319/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 17.5017 - mse: 457.8312\n",
            "Epoch 320/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.6369 - mse: 150.5793\n",
            "Epoch 321/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.6257 - mse: 87.3891\n",
            "Epoch 322/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.7523 - mse: 34.4213\n",
            "Epoch 323/500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 23.8769 - mse: 826.6473\n",
            "Epoch 324/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 6.5827 - mse: 52.1972\n",
            "Epoch 325/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 15.7011 - mse: 357.1023\n",
            "Epoch 326/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.0888 - mse: 67.4170\n",
            "Epoch 327/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 20.2157 - mse: 573.6987\n",
            "Epoch 328/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 13.8279 - mse: 263.7662\n",
            "Epoch 329/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 17.7642 - mse: 463.4828\n",
            "Epoch 330/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 6.3600 - mse: 63.0320\n",
            "Epoch 331/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 21.7519 - mse: 722.9371\n",
            "Epoch 332/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.2420 - mse: 198.2763\n",
            "Epoch 333/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.1790 - mse: 197.0535\n",
            "Epoch 334/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.5349 - mse: 129.5579\n",
            "Epoch 335/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.1596 - mse: 217.9837\n",
            "Epoch 336/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 32.2226 - mse: 1422.9951\n",
            "Epoch 337/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.5676 - mse: 147.8860\n",
            "Epoch 338/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 20.4626 - mse: 611.3803\n",
            "Epoch 339/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 36.5697 - mse: 1972.7013\n",
            "Epoch 340/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.4412 - mse: 146.6977\n",
            "Epoch 341/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.2981 - mse: 137.8105\n",
            "Epoch 342/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 11.7808 - mse: 182.2140\n",
            "Epoch 343/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.6574 - mse: 119.5324\n",
            "Epoch 344/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 5.2876 - mse: 38.3968\n",
            "Epoch 345/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 39.5019 - mse: 2463.1351\n",
            "Epoch 346/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 16.1694 - mse: 381.7823\n",
            "Epoch 347/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.1609 - mse: 245.0909\n",
            "Epoch 348/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.1087 - mse: 120.0469\n",
            "Epoch 349/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 12.9491 - mse: 233.2832\n",
            "Epoch 350/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 16.1665 - mse: 357.2098\n",
            "Epoch 351/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 34.0546 - mse: 1604.8848\n",
            "Epoch 352/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 14.2398 - mse: 279.1785\n",
            "Epoch 353/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 16.6958 - mse: 399.9922\n",
            "Epoch 354/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 19.8495 - mse: 569.8873\n",
            "Epoch 355/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 35.6263 - mse: 1901.5356\n",
            "Epoch 356/500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 7.3612 - mse: 82.8997\n",
            "Epoch 357/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 25.8732 - mse: 1020.9042\n",
            "Epoch 358/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 23.0121 - mse: 762.3987\n",
            "Epoch 359/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 7.5922 - mse: 144.4699\n",
            "Epoch 360/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 22.7494 - mse: 739.9714\n",
            "Epoch 361/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 20.6563 - mse: 617.4523\n",
            "Epoch 362/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.4755 - mse: 55.8555\n",
            "Epoch 363/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 26.4405 - mse: 1047.9880\n",
            "Epoch 364/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 33.4598 - mse: 1619.9473\n",
            "Epoch 365/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.3624 - mse: 137.0308\n",
            "Epoch 366/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 8.1176 - mse: 163.7864\n",
            "Epoch 367/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 31.5796 - mse: 1366.4034\n",
            "Epoch 368/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.3113 - mse: 178.8327\n",
            "Epoch 369/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 15.4731 - mse: 347.1429\n",
            "Epoch 370/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 15.1064 - mse: 322.6710\n",
            "Epoch 371/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 24.6474 - mse: 846.3676\n",
            "Epoch 372/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.0766 - mse: 244.8407\n",
            "Epoch 373/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.6626 - mse: 121.1672\n",
            "Epoch 374/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.5077 - mse: 146.1953\n",
            "Epoch 375/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.7401 - mse: 226.0202\n",
            "Epoch 376/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 15.4849 - mse: 343.3001\n",
            "Epoch 377/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.3770 - mse: 275.3474\n",
            "Epoch 378/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 17.3350 - mse: 452.1428\n",
            "Epoch 379/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 21.5410 - mse: 630.4883\n",
            "Epoch 380/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 35.0745 - mse: 1794.0309\n",
            "Epoch 381/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 7.6949 - mse: 86.1568\n",
            "Epoch 382/500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 12.5581 - mse: 257.8614\n",
            "Epoch 383/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.7018 - mse: 101.6972\n",
            "Epoch 384/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 6.5894 - mse: 58.8983\n",
            "Epoch 385/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.5069 - mse: 185.6676\n",
            "Epoch 386/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 21.0157 - mse: 649.0696\n",
            "Epoch 387/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 25.3279 - mse: 926.4513\n",
            "Epoch 388/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.1201 - mse: 107.4128\n",
            "Epoch 389/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 5.9262 - mse: 48.1410\n",
            "Epoch 390/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 24.9399 - mse: 918.0537\n",
            "Epoch 391/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 5.3383 - mse: 55.3459\n",
            "Epoch 392/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 15.4748 - mse: 344.1707\n",
            "Epoch 393/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 5.3155 - mse: 57.3787\n",
            "Epoch 394/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.0902 - mse: 170.0704\n",
            "Epoch 395/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 14.1821 - mse: 303.2450\n",
            "Epoch 396/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.8618 - mse: 78.6625\n",
            "Epoch 397/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.0388 - mse: 112.7026\n",
            "Epoch 398/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 13.8073 - mse: 285.0831\n",
            "Epoch 399/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 9.7530 - mse: 206.3074\n",
            "Epoch 400/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 23.2993 - mse: 800.0230\n",
            "Epoch 401/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 14.3730 - mse: 327.6050\n",
            "Epoch 402/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.7284 - mse: 92.3649\n",
            "Epoch 403/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.4205 - mse: 157.2351\n",
            "Epoch 404/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.3544 - mse: 166.3927\n",
            "Epoch 405/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 5.8138 - mse: 53.1553\n",
            "Epoch 406/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 17.3152 - mse: 454.5303\n",
            "Epoch 407/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 9.8933 - mse: 210.3550\n",
            "Epoch 408/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 21.8613 - mse: 711.6792\n",
            "Epoch 409/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 32.9579 - mse: 1632.3673\n",
            "Epoch 410/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.9618 - mse: 161.4513\n",
            "Epoch 411/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 14.7364 - mse: 281.1327\n",
            "Epoch 412/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 23.1980 - mse: 779.0099\n",
            "Epoch 413/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.8724 - mse: 220.7476\n",
            "Epoch 414/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 5.3169 - mse: 66.2851\n",
            "Epoch 415/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.9845 - mse: 230.1085\n",
            "Epoch 416/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 27.9657 - mse: 1076.4174\n",
            "Epoch 417/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.0398 - mse: 177.9163\n",
            "Epoch 418/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.4292 - mse: 220.9551\n",
            "Epoch 419/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.7570 - mse: 403.2550\n",
            "Epoch 420/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 25.5950 - mse: 895.9019\n",
            "Epoch 421/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 16.8935 - mse: 419.7533\n",
            "Epoch 422/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6.5194 - mse: 112.3268\n",
            "Epoch 423/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 26.2627 - mse: 958.8283\n",
            "Epoch 424/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 14.3894 - mse: 330.2079\n",
            "Epoch 425/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 6.5461 - mse: 60.9930\n",
            "Epoch 426/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 20.0221 - mse: 563.4625\n",
            "Epoch 427/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 5.4675 - mse: 61.8847\n",
            "Epoch 428/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.9020 - mse: 239.7408\n",
            "Epoch 429/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.7413 - mse: 160.3901\n",
            "Epoch 430/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.3967 - mse: 201.2815\n",
            "Epoch 431/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.5247 - mse: 172.5695\n",
            "Epoch 432/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.4026 - mse: 192.3587\n",
            "Epoch 433/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 9.5572 - mse: 213.7653\n",
            "Epoch 434/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 31.0641 - mse: 1351.7620\n",
            "Epoch 435/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.7320 - mse: 201.3991\n",
            "Epoch 436/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 30.4039 - mse: 1306.0821\n",
            "Epoch 437/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.2410 - mse: 149.3370\n",
            "Epoch 438/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.4983 - mse: 213.7202\n",
            "Epoch 439/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 34.0209 - mse: 1604.1009\n",
            "Epoch 440/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 15.0207 - mse: 292.3250\n",
            "Epoch 441/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 18.6827 - mse: 526.7385\n",
            "Epoch 442/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 23.3211 - mse: 803.3370\n",
            "Epoch 443/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 23.7391 - mse: 801.7246\n",
            "Epoch 444/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.5044 - mse: 178.7519\n",
            "Epoch 445/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 15.2148 - mse: 327.2978\n",
            "Epoch 446/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 19.1407 - mse: 556.2601\n",
            "Epoch 447/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 4.9130 - mse: 39.3332\n",
            "Epoch 448/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.6091 - mse: 183.2649\n",
            "Epoch 449/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 13.8472 - mse: 266.3158\n",
            "Epoch 450/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 17.7478 - mse: 457.3120\n",
            "Epoch 451/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 14.7603 - mse: 321.7629\n",
            "Epoch 452/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 31.1154 - mse: 1384.2671\n",
            "Epoch 453/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 6.3488 - mse: 112.8867\n",
            "Epoch 454/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 28.8322 - mse: 1150.5284\n",
            "Epoch 455/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.3912 - mse: 97.8733\n",
            "Epoch 456/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.8416 - mse: 207.9596\n",
            "Epoch 457/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 15.4993 - mse: 331.3296\n",
            "Epoch 458/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 17.7243 - mse: 475.7519\n",
            "Epoch 459/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 27.5770 - mse: 1086.4917\n",
            "Epoch 460/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.7501 - mse: 219.1155\n",
            "Epoch 461/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.5889 - mse: 223.3980\n",
            "Epoch 462/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 13.2257 - mse: 240.9113\n",
            "Epoch 463/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 30.3476 - mse: 1273.6259\n",
            "Epoch 464/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.3242 - mse: 19.1879\n",
            "Epoch 465/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 15.9370 - mse: 377.0669\n",
            "Epoch 466/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 21.7724 - mse: 696.1475\n",
            "Epoch 467/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 31.6820 - mse: 1510.2935\n",
            "Epoch 468/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.6243 - mse: 179.7524\n",
            "Epoch 469/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.8263 - mse: 233.3513\n",
            "Epoch 470/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.2032 - mse: 14.0647\n",
            "Epoch 471/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 17.3217 - mse: 391.1123\n",
            "Epoch 472/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.9616 - mse: 233.3745\n",
            "Epoch 473/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.3344 - mse: 428.6667\n",
            "Epoch 474/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.4298 - mse: 230.0059\n",
            "Epoch 475/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 17.3095 - mse: 425.5358\n",
            "Epoch 476/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 14.0110 - mse: 281.9855\n",
            "Epoch 477/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 31.3851 - mse: 1360.8681\n",
            "Epoch 478/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.4666 - mse: 138.4424\n",
            "Epoch 479/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.3610 - mse: 193.9732\n",
            "Epoch 480/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 19.0261 - mse: 523.0786\n",
            "Epoch 481/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 16.5661 - mse: 393.6984\n",
            "Epoch 482/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 22.2981 - mse: 747.4349\n",
            "Epoch 483/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 25.8888 - mse: 1000.5072\n",
            "Epoch 484/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 24.0995 - mse: 829.2945\n",
            "Epoch 485/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 5.2883 - mse: 42.5803\n",
            "Epoch 486/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 20.4084 - mse: 584.4698\n",
            "Epoch 487/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 14.3825 - mse: 298.7796\n",
            "Epoch 488/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 32.0213 - mse: 1421.6174\n",
            "Epoch 489/500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 11.1841 - mse: 197.7452\n",
            "Epoch 490/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 11.9448 - mse: 216.1493\n",
            "Epoch 491/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 24.6860 - mse: 895.7283\n",
            "Epoch 492/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 20.3409 - mse: 585.7671\n",
            "Epoch 493/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.5806 - mse: 36.7325\n",
            "Epoch 494/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.1887 - mse: 222.5378\n",
            "Epoch 495/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.4238 - mse: 240.4185\n",
            "Epoch 496/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.0397 - mse: 213.6411\n",
            "Epoch 497/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 18.8880 - mse: 557.6347\n",
            "Epoch 498/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 23.8076 - mse: 844.5661\n",
            "Epoch 499/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.9942 - mse: 125.7282\n",
            "Epoch 500/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 15.1579 - mse: 313.4051\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbefc11bcd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "pH4NimyIcJf9",
        "outputId": "f4952d1c-af00-4bfd-ae39-0f7aaf276703"
      },
      "source": [
        "# predictions\n",
        "y_preds_3 = model_3.predict(X_test)\n",
        "plot_predictions(predictions=y_preds_3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:10 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbefaf8ab00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZMwQEbOgbQt"
      },
      "source": [
        "that is BAD!!!!!\n",
        "\n",
        "problem: **OVERFITTING** \n",
        "\n",
        "\n",
        "LET US CALCULATE THE ERROR "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlOxxTllcJdJ",
        "outputId": "673e9821-53ee-415b-882e-cb85f5a6230e"
      },
      "source": [
        "\n",
        "mae_3 = mae(y_test,y_preds_3)\n",
        "mse_3 = mse(y_test,y_preds_3)\n",
        "mae_3, mse_3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(), dtype=float32, numpy=68.713615>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=4808.0273>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyEHT7SehMOL"
      },
      "source": [
        "🔑 Note: You want to start with small experiments (small models) and make sure they work and then increase their scale when necessary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utuRk1OKcJaR"
      },
      "source": [
        "###Comparing the results of our models\n",
        "\n",
        "We've run a few experimenrs, let's compare the results\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "R3ERCCzxcJXh",
        "outputId": "2deb5d2d-beed-4e83-e48a-225f86015448"
      },
      "source": [
        "# Let's compare our model's results using a pandas dataframe.\n",
        "import pandas as pd\n",
        "\n",
        "model_results = [[\"model_1\",mae_1.numpy(),mse_1.numpy()],\n",
        "                 [\"model_2\",mae_2.numpy(),mse_2.numpy()],\n",
        "                 [\"model_3\", mae_3.numpy(),mse_3.numpy()]]\n",
        "\n",
        "all_results = pd.DataFrame(model_results, columns=[\"model\",\"MAE\",\"MSE\"])\n",
        "all_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>MAE</th>\n",
              "      <th>MSE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>model_1</td>\n",
              "      <td>18.745327</td>\n",
              "      <td>353.573364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>model_2</td>\n",
              "      <td>3.196941</td>\n",
              "      <td>13.070143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>model_3</td>\n",
              "      <td>68.713615</td>\n",
              "      <td>4808.027344</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     model        MAE          MSE\n",
              "0  model_1  18.745327   353.573364\n",
              "1  model_2   3.196941    13.070143\n",
              "2  model_3  68.713615  4808.027344"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYvqA5XehUVE"
      },
      "source": [
        "###LOOKS LIKE model_2 PERFORMED THE BEST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErXjw1KIhUXk",
        "outputId": "93a2ebe7-f56f-402c-e113-5e43f647f153"
      },
      "source": [
        "model_2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_12 (Dense)             (None, 10)                20        \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfwI6tHJhUab"
      },
      "source": [
        "🔑 Note: One of your main goals should be to minimize the time between your experiments. The more experiments you do, the more things you'll figure out which don't work and in turn, get closer to figuring out what does work. Remember the machine learning practioner's motto: \"experiment, experiment, experiment\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46LemZQyhUcs"
      },
      "source": [
        "###Tracking your experiments\n",
        "One really good habit in machine learning modelling is to track the results of your experiments.\n",
        "\n",
        "And when doing so, it can be tedious if you're running lots of experiments.\n",
        "\n",
        "Luckily, there are tools to help us!\n",
        "\n",
        "📖 Resource: As you build more models, you'll want to look into using:\n",
        "\n",
        "* TensorBoard - a component of the TensorFlow library to help track modelling experiments (we'll see this one later).\n",
        "* Weights & Biases - a tool for tracking all of kinds of machine learning experiments (plugs straight into TensorBoard).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nccUqr_fhUe4"
      },
      "source": [
        "###Saving our models:\n",
        "\n",
        "Saving our models allows us to use them outside of Google Colab (or wherever they were trained) such as in a web application or a mobile app.\n",
        "\n",
        "\n",
        "There are two main formats we can save our model's to:\n",
        "\n",
        "* The SavedModel format\n",
        "* The HDF5 format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qmYcwMPhUhF",
        "outputId": "4b24f75a-9ceb-4321-b6f4-5b78c2f9dccc"
      },
      "source": [
        "#save a model using SavedModel format\n",
        "model_2.save(\"best_model_SavedModel_format\") #you get a folder // *default"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model_SavedModel_format/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8FizZGJxMgt"
      },
      "source": [
        "#save a model using HDF5 format\n",
        "model_2.save(\"best_model_HDF5_format.h5\")  #you get a single file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QidSVEdx9cA"
      },
      "source": [
        "###LOADING A MODEL AND RE-EVALUATE IT CORRECTLY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmsIVRMeyahr",
        "outputId": "6b0ad3fa-ec52-4c5f-b64e-c8d9c24f101e"
      },
      "source": [
        "# load in the SavedFormat format model\n",
        "loaded_SavedModel_format = tf.keras.models.load_model(\"/content/best_model_SavedModel_format\")\n",
        "loaded_SavedModel_format.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_12 (Dense)             (None, 10)                20        \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ziVQwjJPyaeo",
        "outputId": "613abf49-8d3d-4faa-c429-7df2928ae093"
      },
      "source": [
        "model_2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_12 (Dense)             (None, 10)                20        \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EYNNFuszXYW"
      },
      "source": [
        "#the summary is same for both, model_2 and SavedFormat format model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0l5-Dg3VyaZ2",
        "outputId": "d57c0b1f-eacf-4a5f-96c9-75c5c3714e78"
      },
      "source": [
        "#compare model_2 predictions with the SavedModel format model predictions.\n",
        "model_2_preds = model_2.predict(X_test)\n",
        "loaded_SavedModel_format_preds = loaded_SavedModel_format.predict(X_test)\n",
        "model_2_preds == loaded_SavedModel_format_preds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0idkAPPyaNY"
      },
      "source": [
        "#let's look at the predictions made by both of the models \n",
        "#model_2_preds, loaded_SavedModel_format_preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHyuDpu1yaIf",
        "outputId": "47dc8355-32a1-4cc4-f9b7-85f1a63492f2"
      },
      "source": [
        "# load in the HDF5 format model\n",
        "loaded_HDF5_format = tf.keras.models.load_model(\"/content/best_model_HDF5_format.h5\")\n",
        "loaded_HDF5_format.summary()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_12 (Dense)             (None, 10)                20        \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1v3M8TS4yYgb",
        "outputId": "647b1a43-a6aa-415b-cfc7-a9e9735ecffb"
      },
      "source": [
        "loaded_HDF5_format_preds = loaded_HDF5_format.predict(X_test)\n",
        "loaded_HDF5_format_preds == model_2_preds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQT7Mr-P4Qh4"
      },
      "source": [
        "###WORKS!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U37DewEU4UKn"
      },
      "source": [
        "###Download a model (or any other file) from Google Colab\n",
        "\n",
        "If you want to download your files from Google Colab:\n",
        "\n",
        "1. You can go to the \"files\" tab and right click on the file you're after and click \"download\".\n",
        "2. Use code (see the cell below).\n",
        "3. Save it to Google Drive by connecting Google Drive and copying it there (see 2nd code cell below)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "s0_Of9tz4UIL",
        "outputId": "29ccf932-b0dc-452b-bef4-51f360919a12"
      },
      "source": [
        "# Download a file from Google Colab\n",
        "from google.colab import files\n",
        "files.download(\"/content/best_model_HDF5_format.h5\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_f0d04352-5851-4ec1-af03-02bf4cf1dc43\", \"best_model_HDF5_format.h5\", 16968)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-AMAB-h4UFA"
      },
      "source": [
        "#Save a file from Google Colab to Google Drive (requires mounting Google Drive)\n",
        "!cp /content/best_model_HDF5_format.h5 /content/drive/MyDrive/DBourke_01tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woT9vsJV4UCt",
        "outputId": "fa2bc991-c0ec-4260-ad78-da417b3c225b"
      },
      "source": [
        "!ls /content/drive/MyDrive/DBourke_01tensorflow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best_model_HDF5_format.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nr7NvIZh4UAX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9hSyzEg4T9T"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}